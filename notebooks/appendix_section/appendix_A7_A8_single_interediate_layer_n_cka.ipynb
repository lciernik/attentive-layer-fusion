{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07ad7bc",
   "metadata": {},
   "source": [
    "## Baseline performances and representational similarities across layers\n",
    "This notebook creates two types of lineplots for the 4 base models and 4 dataset:\n",
    "1. Baseline performances (simple linear probing and AAT) across layers (inlc. the proposed multi-layer fusion approach)\n",
    "2. Representational similarities (CKA and RSA) across layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab56023-e41b-48ce-914a-6f06e76e8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import re\n",
    "import numpy as np\n",
    "from helper import add_additional_info, init_plotting_params, save_or_show, load_sim_matrix\n",
    "from constants import BASE_PATH_PROJECT, FOLDER_SUBSTRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fdd0c-6b58-4e76-b14d-ef80626b7076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_plotting_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab23c79-e2a8-4d65-b3b8-e15e0b836683",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_paths = [\n",
    "    #BASE_PATH_PROJECT / f\"results_{FOLDER_SUBSTRING}_exp\",\n",
    "    BASE_PATH_PROJECT / f\"results_{FOLDER_SUBSTRING}_exp_all_intermediate\",\n",
    "    #BASE_PATH_PROJECT /f \"results_{FOLDER_SUBSTRING}_rebuttal\",\n",
    "    BASE_PATH_PROJECT / f\"results_{FOLDER_SUBSTRING}_combine_aat_ilf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df285b-1b83-48b5-b4d0-a5669e41cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "storing_path = BASE_PATH_PROJECT / f\"results_{FOLDER_SUBSTRING}_rebuttal/plots/appendix_intermediate_layer_alone_aat_ilf\"\n",
    "SAVE = False\n",
    "if SAVE:\n",
    "    storing_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135310b0-b6af-4c45-b35d-c7c1dc3945fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    res = []\n",
    "    for project_path in project_paths:\n",
    "        print(project_path)\n",
    "        for res_path in project_path.rglob('seed_0/results.json'):\n",
    "            if (\"linear_probe/single_model\" not in str(res_path)) and (\"attentive_probe/combined_models\" not in str(res_path)):\n",
    "                continue\n",
    "            \n",
    "            df = pd.read_json(res_path)\n",
    "            #print(df,res_path)\n",
    "            df = add_additional_info(df)\n",
    "            \n",
    "            model_id_n_hopt_slug = \"/\".join(res_path.parts[10:-1])\n",
    "            df['model_id_n_hopt_slug'] = model_id_n_hopt_slug\n",
    "            df['res_folder'] = project_path.name\n",
    "    \n",
    "            res.append(df)\n",
    "    all_results = pd.concat(res).reset_index(drop=True)\n",
    "    all_results[\"probe_type\"]= \"cae\"\n",
    "runs_rebuttal = pd.read_pickle(BASE_PATH_PROJECT / f\"results_{FOLDER_SUBSTRING}_rebuttal/aggregated/all_runs_rebuttal.pkl\")\n",
    "runs_old = pd.read_pickle(BASE_PATH_PROJECT / f\"results_{FOLDER_SUBSTRING}_exp/aggregated\" / f'all_runs_v11.pkl')\n",
    "runs_old[\"probe_type\"]=\"cae\"\n",
    "all_results = pd.concat([all_results,runs_old,runs_rebuttal]).reset_index(drop=True)\n",
    "aat_ilf = all_results[all_results[\"Experiment\"]==\"All tokens from quarterly blocks (attentive)\"]\n",
    "all_results = all_results[all_results[\"Experiment\"]!=\"All tokens from quarterly blocks (attentive)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497ac65-f868-4b03-9fab-9451ad33943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = ['wds/vtab/cifar100', 'wds/vtab/eurosat', 'wds/gtsrb', 'wds/fer2013']\n",
    "ds_list_relpaced = ['wds_vtab_cifar100', 'wds_vtab_eurosat', 'wds_gtsrb', 'wds_fer2013']\n",
    "model_list = ['CLIP-B-16', 'DINOv2-B-14', 'ViT-B-16', 'MAE-B-16']\n",
    "all_results = all_results[\n",
    "    all_results['dataset'].isin(ds_list) & \\\n",
    "    all_results['base_model_fmt'].isin(model_list)\n",
    "].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83734889-385c-45ed-a804-e8cd6e8fbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['block_layer'] = all_results['model_ids'].apply(lambda x: eval(x)[0].split(\"@\")[1] if len(eval(x))==1 else \"multi\")\n",
    "def parse_block_layer(block_layer):\n",
    "    if block_layer in ['norm', 'visual']:\n",
    "        return \"last\"\n",
    "    match = re.search(r'\\.(\\d+)\\.', block_layer)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    if \"multi\" in block_layer:\n",
    "        return \"multi\"\n",
    "    return 'unknown'\n",
    "\n",
    "all_results['block_layer'] = all_results['block_layer'].apply(parse_block_layer)\n",
    "all_results = all_results[all_results['block_layer'] != '0' ].copy().reset_index(drop=True)\n",
    "all_results.loc[:,'layer_types'] = all_results.loc[:,'layer_types'].map({'cls+avg_pool': \"Linear probe on CLS and AP\", 'avg_pool': \"Linear probe on AP\", 'cls': \"Linear probe on CLS\", \"all_tokens_last_layer\": \"AAT\"})\n",
    "all_results.loc[:,'layer_types'] = all_results.loc[:,'layer_types'].map({\"Linear probe on CLS and AP\": \"Single Layer (CLS+AP, Linear)\" ,\"Linear probe on AP\": \"Single Layer (AP, Linear)\", \"Linear probe on CLS\":\"Single Layer (CLS, Linear)\",\n",
    "                                                                         \"AAT\":\"Single Layer (all tokens, attentive)\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c1e75-4423-4ad0-b026-f59f7b708552",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = BASE_PATH_PROJECT / f\"model_similarities_{FOLDER_SUBSTRING}\"\n",
    "sim_metrics = [\n",
    "    'cka_kernel_linear_unbiased',\n",
    "    'cka_kernel_rbf_unbiased_sigma_0.2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23ebb8-22aa-4c9f-96c3-aea670bbf782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(item):\n",
    "\n",
    "    if '_cls@' in item:\n",
    "        token_type = 0  \n",
    "    elif '_ap@' in item:\n",
    "        token_type = 1 \n",
    "    else:\n",
    "        token_type = 2\n",
    "    match = re.search(r'\\.(\\d+)\\.', item)\n",
    "    if match:\n",
    "        block_num = int(match.group(1))\n",
    "    else:\n",
    "        block_num = np.inf \n",
    "    return (token_type, block_num)\n",
    "\n",
    "res = dict()\n",
    "for path in base_path.rglob(\"similarity_matrix.pt\"):\n",
    "    ds = path.parts[5]\n",
    "    if ds not in ds_list_relpaced:\n",
    "        continue\n",
    "    sim_metric = path.parts[6]\n",
    "    model = path.parts[7]\n",
    "    curr_sim_mat = load_sim_matrix(path.parent, allowed_models=None)\n",
    "    sorted_list = sorted(curr_sim_mat.index.to_list(), key=sort_key)\n",
    "    curr_sim_mat = curr_sim_mat.loc[sorted_list, sorted_list]\n",
    "    np.fill_diagonal(curr_sim_mat.values, 1)\n",
    "    if sim_metric not in res.keys():\n",
    "        res[sim_metric] = {}\n",
    "    if ds not in res[sim_metric].keys(): \n",
    "        res[sim_metric][ds] = {}\n",
    "    res[sim_metric][ds][model] = curr_sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaefe7d-1805-49fd-89b3-ed4ed7252f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['text.usetex'] = False\n",
    "order = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', 'last']\n",
    "SIM_METRIC = sim_metrics[0] \n",
    "offset = 2\n",
    "color_map = {\n",
    "    'CLIP-B-16':list(plt.cm.tab20c.colors)[8 + offset], \n",
    "    'DINOv2-B-14':list(plt.cm.tab20c.colors)[12+ offset], \n",
    "    'ViT-B-16':list(plt.cm.tab20b.colors)[12+ offset], \n",
    "    'OpenCLIP_ViT-B-16_openai':list(plt.cm.tab20c.colors)[8+ offset], \n",
    "    'dinov2-vit-base-p14':list(plt.cm.tab20c.colors)[12+ offset], \n",
    "    'vit_base_patch16_224': list(plt.cm.tab20b.colors)[12+ offset], \n",
    "    'MAE-B-16': list(plt.cm.tab20b.colors)[16+ offset],\n",
    "    'mae-vit-base-p16': list(plt.cm.tab20b.colors)[16+ offset],\n",
    "}\n",
    "#all_results_filtered = all_results[all_results[\"layer_types\"].isin([\"Linear probe on AP\", \"Linear probe on CLS\", \"AAT\"]) ]\n",
    "all_results_filtered = all_results[all_results[\"layer_types\"].isin([\"Single Layer (AP, Linear)\", \"Single Layer (CLS, Linear)\", \"Single Layer (all tokens, attentive)\"]) ]\n",
    "\n",
    "g = sns.relplot(\n",
    "    all_results_filtered.sort_values(by='block_layer', key=lambda x: x.apply(lambda y: order.index(y))),\n",
    "    x='block_layer', \n",
    "    y='test_lp_bal_acc1',\n",
    "    hue='layer_types',               # <--- NEW\n",
    "    hue_order=[\"Single Layer (AP, Linear)\", \"Single Layer (CLS, Linear)\", \"Single Layer (all tokens, attentive)\"],#[\"Linear probe on AP\", \"Linear probe on CLS\", \"AAT\"], \n",
    "    #col='dataset_fmt',\n",
    "    #row='base_model_fmt',            # <--- NEW\n",
    "    row='dataset_fmt',\n",
    "    col='base_model_fmt',            # <--- NEW\n",
    "    col_order=[ \"CLIP-B-16\", \"DINOv2-B-14\", \"ViT-B-16\", \"MAE-B-16\" ],\n",
    "    facet_kws={'sharey':\"row\"},\n",
    "    kind='line',\n",
    "    height=3.25,\n",
    "    aspect=1.1,\n",
    "    linewidth=2,\n",
    ")\n",
    "# --- Add a square marker on the last point for \"Single Layer (all tokens, attentive)\" ---\n",
    "target_layers = [\n",
    "    \"Single Layer (AP, Linear)\",\n",
    "    \"Single Layer (CLS, Linear)\",\n",
    "    \"Single Layer (all tokens, attentive)\"\n",
    "]\n",
    "\n",
    "hue_order = [\"Single Layer (AP, Linear)\", \"Single Layer (CLS, Linear)\", \"Single Layer (all tokens, attentive)\"]\n",
    "\n",
    "# Grab the palette seaborn used for the current plot (number of colors = number of hues)\n",
    "palette = sns.color_palette(n_colors=len(hue_order))\n",
    "palette_map = dict(zip(hue_order, palette))\n",
    "\n",
    "for i_row in range(g.axes.shape[0]):\n",
    "    for j_col in range(g.axes.shape[1]):\n",
    "        ax = g.axes[i_row, j_col]\n",
    "\n",
    "        for layer_type in target_layers:\n",
    "\n",
    "            # data subset in this facet + this layer type\n",
    "            facet_data = all_results_filtered[\n",
    "                (all_results_filtered[\"dataset_fmt\"] == g.row_names[i_row]) &\n",
    "                (all_results_filtered[\"base_model_fmt\"] == g.col_names[j_col]) &\n",
    "                (all_results_filtered[\"layer_types\"] == layer_type)\n",
    "            ].sort_values(by='block_layer', key=lambda x: x.apply(lambda y: order.index(y)))\n",
    "\n",
    "            if len(facet_data) == 0:\n",
    "                print(\"last not found\", layer_type)\n",
    "                continue\n",
    "\n",
    "            # last point\n",
    "            last_x_label = facet_data[\"block_layer\"].iloc[-1]\n",
    "            last_y = facet_data[\"test_lp_bal_acc1\"].iloc[-1]\n",
    "            last_x = order.index(last_x_label)\n",
    "\n",
    "\n",
    "            #color = line.get_color()\n",
    "            \n",
    "            color = palette_map.get(layer_type, \"black\")\n",
    "\n",
    "            # draw square marker\n",
    "            ax.scatter(\n",
    "                [last_x], [last_y],\n",
    "                marker=\"x\",\n",
    "                s=80,\n",
    "                facecolor=color,\n",
    "                #edgecolor=\"black\",\n",
    "                zorder=10,\n",
    "            )\n",
    "\n",
    "def get_similarities(curr_sim_mat, is_cls=False):\n",
    "    n_layers = curr_sim_mat.shape[0]\n",
    "    if is_cls:\n",
    "        return curr_sim_mat.iloc[(n_layers // 2)-1, 1 : (n_layers // 2)]\n",
    "    else:\n",
    "        return curr_sim_mat.iloc[n_layers-1, (n_layers // 2) + 1 :]        \n",
    "\n",
    "def plot_cka_new(data, *args, **kwargs):\n",
    "\n",
    "    # ------- find dataset -------\n",
    "    ds = data['dataset'].unique()\n",
    "    assert len(ds) == 1\n",
    "    ds = ds[0].replace('/', '_')\n",
    "\n",
    "    # ------- find layer type (to detect CLS only) -------\n",
    "    layer_type = data['layer_types'].unique()\n",
    "    \n",
    "    if len(layer_type) != 1:\n",
    "        print(layer_type)\n",
    "        layer_type = [\"Single Layer (CLS, Linear)\"]#[\"Linear probe on CLS\"]\n",
    "    layer_type = layer_type[0]\n",
    "\n",
    "    if layer_type != \"Single Layer (CLS, Linear)\":#\"Linear probe on CLS\":\n",
    "        return  # <-- Only plot the CLS-based CKA line\n",
    "\n",
    "    # ------- find model (one model per row now) -------\n",
    "    base_model = data['base_model'].unique()\n",
    "    assert len(base_model) == 1\n",
    "    base_model = base_model[0]\n",
    "\n",
    "    # ------- extract CKA similarity -------\n",
    "    curr_sim_mat = res[SIM_METRIC][ds][f\"{base_model}_both\"]\n",
    "    \n",
    "    # CLS similarities come from the middle block:\n",
    "    n_layers = curr_sim_mat.shape[0]\n",
    "    curr_sims = curr_sim_mat.iloc[(n_layers // 2) - 1, 1:(n_layers // 2)]\n",
    "\n",
    "    # ------- plot on current axis -------\n",
    "    ax = plt.gca()\n",
    "    ax.plot(\n",
    "        ax.get_xticks(),\n",
    "        curr_sims,\n",
    "        color=\"black\",\n",
    "        linestyle=':',\n",
    "        linewidth=2,\n",
    "        zorder=-1\n",
    "    )\n",
    "\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.set_xlabels(\"\")\n",
    "\n",
    "\n",
    "for i, layer_type in enumerate(g.row_names):\n",
    "    #g.axes[i, 0].set_ylabel(f\"{layer_type}\\n\\nTest bal. accuracy (solid) \\n\\n CKA similarity (dotted)\")\n",
    "    g.axes[i, 0].set_ylabel(f\"{layer_type}\\n\\nTest bal. accuracy \")\n",
    "\n",
    "for i in range(len(g.row_names)):\n",
    "    for j in range(1, g.axes.shape[1]):\n",
    "        g.axes[i, j].set_ylabel(\"\")\n",
    "\n",
    "for i in range(1, g.axes.shape[0]): \n",
    "    for j in range(0, g.axes.shape[1]):\n",
    "        g.axes[i, j].set_title(\"\")\n",
    "\n",
    "#g.map_dataframe(plot_cka_new)\n",
    "\n",
    "g.fig.tight_layout()\n",
    "\n",
    "baseline_results = all_results[all_results[\"layer_types\"].isin([ \"Single Layer (CLS+AP, Linear)\"]) &\\\n",
    "    all_results[\"nr_layers\"].isin([24]) &\\\n",
    "    #all_results[\"base_model\"].isin([\"dinov2-vit-base-p14\"]) \n",
    "    all_results[\"task\"].isin([\"attentive_probe\"]) &\\\n",
    "    all_results[\"probe_type\"].isin([\"cae\"])\n",
    "    ]#[\"model_ids\"].value_counts()\n",
    "\n",
    "\n",
    "def plot_baseline(data, *args, **kwargs):\n",
    "    # dataset in this facet\n",
    "    ds = data['dataset'].unique()\n",
    "    assert len(ds) == 1\n",
    "    ds = ds[0]\n",
    "\n",
    "    # model in this facet\n",
    "    model = data['base_model'].unique()\n",
    "    assert len(model) == 1\n",
    "    model = model[0]\n",
    "\n",
    "    # look up the baseline value\n",
    "    row = baseline_results[\n",
    "        (baseline_results[\"dataset\"] == ds) &\n",
    "        (baseline_results[\"base_model\"] == model)\n",
    "    ]\n",
    "\n",
    "    if len(row) == 0:\n",
    "        print(\"no Baseline?\")\n",
    "        return  # no baseline for this combination\n",
    "    baseline_value = row[\"test_lp_bal_acc1\"].iloc[0]\n",
    "\n",
    "    ax = plt.gca()\n",
    "    xticks = ax.get_xticks()\n",
    "    xmin = xticks[0]\n",
    "    xmax = xticks[-1]\n",
    "\n",
    "    # draw the horizontal baseline\n",
    "    ax.hlines(\n",
    "        y=baseline_value,\n",
    "        xmin=xmin,\n",
    "        xmax=xmax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2.5,\n",
    "        zorder=-2\n",
    "    )\n",
    "    if True:\n",
    "        row_2 = aat_ilf[(aat_ilf[\"dataset\"] == ds) &\n",
    "        (aat_ilf[\"base_model\"] == model)]\n",
    "        if len(row_2) == 0:\n",
    "            print(\"no Baseline?\")\n",
    "            return  # no baseline for this combination\n",
    "        baseline_value = row_2[\"test_lp_bal_acc1\"].iloc[0]\n",
    "        # draw the horizontal baseline\n",
    "        ax.hlines(\n",
    "            y=baseline_value,\n",
    "            xmin=xmin,\n",
    "            xmax=xmax,\n",
    "            color=\"purple\",\n",
    "            linestyle=\"-.\",\n",
    "            linewidth=2.5,\n",
    "            zorder=-2\n",
    "        )\n",
    "g.map_dataframe(plot_baseline)\n",
    "#sns.move_legend(g, loc=\"upper left\", bbox_to_anchor=(0.85,0.65), title=\"Model\")\n",
    "\n",
    "baseline_handle = Line2D(\n",
    "    [], [], \n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"All Layers (CLS+AP, attentive)\"\n",
    ")\n",
    "baseline_handle_2 = Line2D(\n",
    "    [], [], \n",
    "    color=\"purple\",\n",
    "    linestyle=\"-.\",\n",
    "    linewidth=2,\n",
    "    label=\"Quartely Layer (All Tokens, attentive)\"\n",
    ")\n",
    "# Remove panel-level legend\n",
    "if g._legend is not None:\n",
    "    g._legend.remove()\n",
    "\n",
    "# Extract handles from any subplot\n",
    "handles, labels = g.axes[0][0].get_legend_handles_labels()\n",
    "\n",
    "# Add baseline\n",
    "handles.append(baseline_handle)\n",
    "labels.append(\"All Layers (CLS+AP, attentive)\")\n",
    "handles.append(baseline_handle_2)\n",
    "labels.append(\"Quartely Layer (All Tokens, attentive)\")\n",
    "\n",
    "\n",
    "# Add bottom legend\n",
    "g.fig.legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    loc=\"lower center\",\n",
    "    ncol=2,#len(labels),\n",
    "    frameon=False,\n",
    "    bbox_to_anchor=(0.44, -0.06),\n",
    ")\n",
    "# cka_legend_elements = [Line2D([0], [0], color=color_map[model], linestyle=':', \n",
    "#                              linewidth=2, label=model) \n",
    "#                       for model in model_list]\n",
    "\n",
    "# cka_legend = g.fig.legend(handles=cka_legend_elements, \n",
    "#                           title=\"CKA similarity\",\n",
    "#                           loc=\"upper left\",\n",
    "#                           frameon=False,\n",
    "#                           bbox_to_anchor=(1, 0.8))  # Position below the first legend\n",
    "\n",
    "fn = storing_path / f'cka_{\"local\" if \"rbf\" in SIM_METRIC else \"global\"}_vs_test_bal_acc_intermediate_layers_with_aatilf.pdf'\n",
    "save_or_show(g.fig, fn, SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1dece-fadf-4f04-9483-9862c92c4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"layer_types\"].value_counts()\n",
    "all_results[all_results[\"layer_types\"].isin([ \"Linear probe on CLS and AP\"])& \\\n",
    "    all_results[\"nr_layers\"].isin([24]) &\\\n",
    "    #all_results[\"base_model\"].isin([\"dinov2-vit-base-p14\"]) \n",
    "    all_results[\"task\"].isin([\"attentive_probe\"])\n",
    "    ]#[\"model_ids\"].value_counts()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df544fbd-c80c-442f-a5d8-36e0b3af4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "order = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', 'last']\n",
    "def extract_cka_df(SIM_METRIC, res, model_list, model_list_fmt, datasets,datasets_fmt, order):\n",
    "    rows = []\n",
    "\n",
    "    for ds,ds_fmt in zip(datasets,datasets_fmt):\n",
    "        for model,model_fmt in zip(model_list,model_list_fmt):\n",
    "            mat = res[SIM_METRIC][ds.replace(\"/\", \"_\")][f\"{model}_both\"]\n",
    "            n_layers = mat.shape[0]\n",
    "            sims = mat.iloc[(n_layers // 2)-1, 1 : (n_layers // 2)]  # CLS similarities only\n",
    "\n",
    "            for blk, value in zip(order[:len(sims)], sims):\n",
    "                rows.append({\n",
    "                    \"dataset_fmt\": ds_fmt,\n",
    "                    \"base_model_fmt\": model_fmt,\n",
    "                    \"block_layer\": blk,\n",
    "                    \"cka_sim\": value,\n",
    "                    \"plot_type\": \"CKA\"\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "offset = 2\n",
    "color_map = {\n",
    "    'CLIP-B-16':list(plt.cm.tab20c.colors)[8 + offset], \n",
    "    'DINOv2-B-14':list(plt.cm.tab20c.colors)[12+ offset], \n",
    "    'ViT-B-16':list(plt.cm.tab20b.colors)[12+ offset], \n",
    "    'OpenCLIP_ViT-B-16_openai':list(plt.cm.tab20c.colors)[8+ offset], \n",
    "    'dinov2-vit-base-p14':list(plt.cm.tab20c.colors)[12+ offset], \n",
    "    'vit_base_patch16_224': list(plt.cm.tab20b.colors)[12+ offset], \n",
    "    'MAE-B-16': list(plt.cm.tab20b.colors)[16+ offset],\n",
    "    'mae-vit-base-p16': list(plt.cm.tab20b.colors)[16+ offset],\n",
    "}\n",
    "SAVE=True\n",
    "mask = (\n",
    "    (all_results[\"base_model_fmt\"] != \"MAE-B-16\") &\n",
    "    (all_results[\"layer_types\"] == \"Single Layer (CLS, Linear)\")\n",
    ") | (\n",
    "    (all_results[\"base_model_fmt\"] == \"MAE-B-16\") &\n",
    "    (all_results[\"layer_types\"] == \"Single Layer (AP, Linear)\")\n",
    ")\n",
    "acc_df = (\n",
    "    all_results[mask]#[all_results[\"layer_types\"] == \"Single Layer (CLS, Linear)\"]\n",
    "    .assign(plot_type=\"Accuracy\")\n",
    "    .rename(columns={\"test_lp_bal_acc1\": \"value\"})\n",
    ")[[\"dataset_fmt\",\"base_model_fmt\",\"block_layer\",\"value\",\"plot_type\"]]\n",
    "\n",
    "\n",
    "for SIM_METRIC in sim_metrics:\n",
    "    cka_df = extract_cka_df(\n",
    "        SIM_METRIC,\n",
    "        res,\n",
    "        all_results[\"base_model\"].unique(),\n",
    "        all_results[\"base_model_fmt\"].unique(),\n",
    "        all_results[\"dataset\"].unique(),\n",
    "        all_results[\"dataset_fmt\"].unique(),\n",
    "        order\n",
    "    )\n",
    "    cka_df = cka_df.rename(columns={\"cka_sim\": \"value\"})\n",
    "    plot_df = pd.concat([acc_df, cka_df], ignore_index=True)\n",
    "    g = sns.relplot(\n",
    "        plot_df.sort_values(by=\"block_layer\", key=lambda x: x.map({k: i for i, k in enumerate(order)})),\n",
    "        x=\"block_layer\",\n",
    "        y=\"value\",\n",
    "        hue=\"base_model_fmt\",\n",
    "        hue_order=model_list,\n",
    "        col=\"dataset_fmt\",\n",
    "        row=\"plot_type\",           # <--- 2 rows: Accuracy, CKA\n",
    "        row_order = [\"Accuracy\",\"CKA\"],\n",
    "        kind=\"line\",\n",
    "        facet_kws={\"sharey\": False},\n",
    "        palette=color_map,\n",
    "        linewidth=2,\n",
    "        height=3.0,\n",
    "        aspect=1.2,\n",
    "    )\n",
    "\n",
    "    g.set_titles(\"{col_name}\")\n",
    "    g.set_xlabels(\"\")\n",
    "    \n",
    "    \n",
    "    #for i, layer_type in enumerate(g.row_names):\n",
    "        #g.axes[i, 0].set_ylabel(f\"{layer_type}\\n\\nTest bal. accuracy (solid) \\n\\n CKA similarity (dotted)\")\n",
    "    g.axes[0, 0].set_ylabel(f\"Test bal. accuracy\")\n",
    "    g.axes[1, 0].set_ylabel(f\"CKA similarity\")\n",
    "    \n",
    "    for i in range(len(g.row_names)):\n",
    "        for j in range(1, g.axes.shape[1]):\n",
    "            g.axes[i, j].set_ylabel(\"\")\n",
    "    \n",
    "    for i in range(1, g.axes.shape[0]): \n",
    "        for j in range(0, g.axes.shape[1]):\n",
    "            g.axes[i, j].set_title(\"\")\n",
    "    for (row_name, col_name), ax in g.axes_dict.items():\n",
    "        if row_name == \"CKA\":\n",
    "            for line in ax.lines:\n",
    "                line.set_linestyle(\"-.\")\n",
    "                line.set_linewidth(2)\n",
    "    g.fig.tight_layout()\n",
    "    \n",
    "    #sns.move_legend(g, loc=\"upper left\", bbox_to_anchor=(1,1), title=\"Base Model\")\n",
    "    handles, labels = g.axes[0,0].get_legend_handles_labels()\n",
    "\n",
    "    g.fig.legend(\n",
    "        handles=handles,\n",
    "        labels=labels,\n",
    "        loc=\"lower center\",\n",
    "        ncol=len(labels),\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.5, -0.05)\n",
    "    )\n",
    "    \n",
    "    g._legend.remove()\n",
    "\n",
    "    \n",
    "    # cka_legend_elements = [Line2D([0], [0], color=color_map[model], linestyle=':', \n",
    "    #                              linewidth=2, label=model) \n",
    "    #                       for model in model_list]\n",
    "    \n",
    "    # cka_legend = g.fig.legend(handles=cka_legend_elements, \n",
    "    #                           title=\"CKA similarity\",\n",
    "    #                           loc=\"upper left\",\n",
    "    #                           frameon=False,\n",
    "    #                           bbox_to_anchor=(1, 0.8))  # Position below the first legend\n",
    "    \n",
    "    fn = storing_path / f'cka_{\"local\" if \"rbf\" in SIM_METRIC else \"global\"}_vs_test_bal_acc_intermediate_layers_updated.pdf'\n",
    "    save_or_show(g.fig, fn, SAVE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95243ae-a684-4228-b953-ab0dac6eb4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rep2rep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
