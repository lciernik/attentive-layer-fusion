{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d4ea5f",
   "metadata": {},
   "source": [
    "# Task-Specific Performance Gains Table Generation\n",
    "\n",
    "This notebook generatestables showing task-specific performance gains across different representation methods.\n",
    "\n",
    "- **Data**\n",
    "    - **Input**: `complete_set_of_run.pkl` - 9 vision transformers, 20 datasets\n",
    "    - **Methods**: 6 representation approaches (CLS baseline, attentive probes, linear/attentive multi-layer)\n",
    "- **Statistical Analysis**\n",
    "    - **Wilcoxon signed-rank tests**: Compare each method against the best-performing method per dataset\n",
    "    - **Significance threshold**: p < 0.05\n",
    "    - **Metrics**: Train and test balanced accuracy gains\n",
    "\n",
    "- **Table Generation**: Creates two LaTeX table versions:\n",
    "    1. **Statistical significance formatting**: Bold for statistically significant improvements over best method\n",
    "    2. **Ranking-based formatting**: Bold for best performance, underline for second-best performance\n",
    "\n",
    "- **Output**: LaTeX tables showing mean ± standard deviation performance gains across models, with datasets sorted by domain category and statistical formatting applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb033029-6c6b-43ab-a49e-cc9ec5ef747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "from constants import base_model_name_mapping, BASE_PATH_PROJECT, FOLDER_SUBSTRING, experiment_with_probe_type_order_list, experiment_order_list\n",
    "from helper import style_multimodel_heatmap, init_plotting_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100ab5a4-5ef7-4baa-aa8b-b6e5319a17f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"agg.path.chunksize\": 0,\n",
      "  \"axes.labelsize\": 13.0,\n",
      "  \"axes.titlesize\": 14.0,\n",
      "  \"axes3d.trackballsize\": 0.667,\n",
      "  \"boxplot.flierprops.markersize\": 6.0,\n",
      "  \"boxplot.meanprops.markersize\": 6.0,\n",
      "  \"errorbar.capsize\": 0.0,\n",
      "  \"figure.figsize\": [\n",
      "    6.4,\n",
      "    4.8\n",
      "  ],\n",
      "  \"figure.labelsize\": \"large\",\n",
      "  \"figure.titlesize\": \"large\",\n",
      "  \"font.cursive\": [\n",
      "    \"Apple Chancery\",\n",
      "    \"Textile\",\n",
      "    \"Zapf Chancery\",\n",
      "    \"Sand\",\n",
      "    \"Script MT\",\n",
      "    \"Felipa\",\n",
      "    \"Comic Neue\",\n",
      "    \"Comic Sans MS\",\n",
      "    \"cursive\"\n",
      "  ],\n",
      "  \"font.family\": [\n",
      "    \"sans-serif\"\n",
      "  ],\n",
      "  \"font.fantasy\": [\n",
      "    \"Chicago\",\n",
      "    \"Charcoal\",\n",
      "    \"Impact\",\n",
      "    \"Western\",\n",
      "    \"xkcd script\",\n",
      "    \"fantasy\"\n",
      "  ],\n",
      "  \"font.monospace\": [\n",
      "    \"DejaVu Sans Mono\",\n",
      "    \"Bitstream Vera Sans Mono\",\n",
      "    \"Computer Modern Typewriter\",\n",
      "    \"Andale Mono\",\n",
      "    \"Nimbus Mono L\",\n",
      "    \"Courier New\",\n",
      "    \"Courier\",\n",
      "    \"Fixed\",\n",
      "    \"Terminal\",\n",
      "    \"monospace\"\n",
      "  ],\n",
      "  \"font.sans-serif\": [\n",
      "    \"DejaVu Sans\",\n",
      "    \"Bitstream Vera Sans\",\n",
      "    \"Computer Modern Sans Serif\",\n",
      "    \"Lucida Grande\",\n",
      "    \"Verdana\",\n",
      "    \"Geneva\",\n",
      "    \"Lucid\",\n",
      "    \"Arial\",\n",
      "    \"Helvetica\",\n",
      "    \"Avant Garde\",\n",
      "    \"sans-serif\"\n",
      "  ],\n",
      "  \"font.serif\": [\n",
      "    \"DejaVu Serif\",\n",
      "    \"Bitstream Vera Serif\",\n",
      "    \"Computer Modern Roman\",\n",
      "    \"New Century Schoolbook\",\n",
      "    \"Century Schoolbook L\",\n",
      "    \"Utopia\",\n",
      "    \"ITC Bookman\",\n",
      "    \"Bookman\",\n",
      "    \"Nimbus Roman No9 L\",\n",
      "    \"Times New Roman\",\n",
      "    \"Times\",\n",
      "    \"Palatino\",\n",
      "    \"Charter\",\n",
      "    \"serif\"\n",
      "  ],\n",
      "  \"font.size\": 10.0,\n",
      "  \"font.stretch\": \"normal\",\n",
      "  \"font.style\": \"normal\",\n",
      "  \"font.variant\": \"normal\",\n",
      "  \"font.weight\": \"normal\",\n",
      "  \"legend.fontsize\": 12.0,\n",
      "  \"legend.title_fontsize\": 13.0,\n",
      "  \"lines.markersize\": 6.0,\n",
      "  \"mathtext.fontset\": \"dejavusans\",\n",
      "  \"pdf.fonttype\": 42,\n",
      "  \"pdf.use14corefonts\": false,\n",
      "  \"pgf.rcfonts\": true,\n",
      "  \"ps.fonttype\": 42,\n",
      "  \"ps.papersize\": \"letter\",\n",
      "  \"svg.fonttype\": \"path\",\n",
      "  \"xtick.labelsize\": 12.0,\n",
      "  \"xtick.major.size\": 3.5,\n",
      "  \"xtick.minor.size\": 2.0,\n",
      "  \"ytick.labelsize\": 12.0,\n",
      "  \"ytick.major.size\": 3.5,\n",
      "  \"ytick.minor.size\": 2.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "init_plotting_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985fc8b-a3f7-4a98-bbf1-c92639b1bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = 'both'\n",
    "\n",
    "base_storing_path = BASE_PATH_PROJECT / f'results_{FOLDER_SUBSTRING}_rebuttal/plots' \n",
    "\n",
    "if SAVE:\n",
    "    base_storing_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4100ec-6930-4df5-8229-6fb059a3a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs= pd.read_pickle(BASE_PATH_PROJECT / f'results_{FOLDER_SUBSTRING}_rebuttal/aggregated/complete_set_of_run.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c424cfb4-ae4d-48fa-9db4-b73f84acea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_cols = [\n",
    "    'abs_perf_gain_train_lp_bal_acc1',\n",
    "    'abs_perf_gain_test_lp_bal_acc1',\n",
    "    'test_lp_bal_acc1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b46cb3-4f8f-47a1-a3d5-4c38153b97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs[metrics_cols] = all_runs[metrics_cols].astype(float)\n",
    "all_runs[metrics_cols] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f05e526-2ebe-4d44-99c4-07ea230bcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_experiments = [\n",
    "'CLS last layer',\n",
    "'All tokens last layer (attentive)',\n",
    "'CLS+AP last layer (linear)',\n",
    "'CLS+AP layers from all blocks (linear)',\n",
    "'CLS+AP last layer (attentive)',\n",
    "'CLS+AP layers from all blocks (attentive)', \n",
    "]\n",
    "not_allowed_models = ['mae-vit-base-p16', 'mae-vit-large-p16']\n",
    "\n",
    "all_runs = all_runs[all_runs['Experiment'].isin(allowed_experiments) & (~all_runs['base_model'].isin(not_allowed_models))].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35bfc828-a26e-4002-b13e-c29ae6116d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = all_runs.drop(index=all_runs[(all_runs['nr_layers'] == 1) & all_runs['contains_intermediate']].index).copy().reset_index(drop=True)\n",
    "all_runs = all_runs[all_runs['probe_type'].isin(['cae', 'linear'])].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e95d21-17ef-4e61-8359-791786f4d9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment\n",
       "All tokens last layer (attentive)            9\n",
       "CLS last layer                               9\n",
       "CLS+AP last layer (attentive)                9\n",
       "CLS+AP last layer (linear)                   9\n",
       "CLS+AP layers from all blocks (attentive)    9\n",
       "CLS+AP layers from all blocks (linear)       9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs[[\"dataset\", \"Experiment\"]].value_counts().sort_index().loc[('wds/imagenet1k',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a1b38b-0051-4a5e-b770-ce5b8b93ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## temporarily filter wds/imagenet1k with All tokens last layer (attentive) \n",
    "# idx_to_drop = all_runs[(all_runs['dataset']=='wds/imagenet1k') & \\\n",
    "#                        (all_runs['Experiment']=='All tokens last layer (attentive)')].index\n",
    "# all_runs = all_runs.drop(index = idx_to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9090f-0933-4b91-9f9b-cc5a7778c62f",
   "metadata": {},
   "source": [
    "### Table version with statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd49a42-969c-48f0-8175-f89e3f3c3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_if_is_bold(mean_val, std_val, is_significant):\n",
    "    formatted = f\"{mean_val:.2f} ± {std_val:.2f}\"\n",
    "    if is_significant:\n",
    "        return formatted\n",
    "    else:\n",
    "        return f\"\\\\textbf{{{formatted}}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26f67e6-bf0b-48a6-9447-0a4b14377bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_cols = [\n",
    "    'abs_perf_gain_train_lp_bal_acc1_mod',\n",
    "    'abs_perf_gain_test_lp_bal_acc1_mod',\n",
    "]\n",
    "\n",
    "all_runs['abs_perf_gain_train_lp_bal_acc1_mod'] = all_runs['abs_perf_gain_train_lp_bal_acc1'].copy().astype(float)\n",
    "all_runs['abs_perf_gain_test_lp_bal_acc1_mod'] = all_runs['abs_perf_gain_test_lp_bal_acc1'].copy().astype(float)\n",
    "\n",
    "all_runs.loc[all_runs['Experiment'] == 'CLS last layer', 'abs_perf_gain_train_lp_bal_acc1_mod'] = all_runs.loc[all_runs['Experiment'] == 'CLS last layer', 'train_lp_bal_acc1'].astype(float)\n",
    "all_runs.loc[all_runs['Experiment'] == 'CLS last layer', 'abs_perf_gain_test_lp_bal_acc1_mod'] = all_runs.loc[all_runs['Experiment'] == 'CLS last layer', 'test_lp_bal_acc1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74717d7e-02e3-4122-b30b-c2482ab3d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLS last layer',\n",
       " 'All tokens last layer (attentive)',\n",
       " 'CLS+AP last layer (linear)',\n",
       " 'CLS+AP layers from all blocks (linear)',\n",
       " 'CLS+AP last layer (attentive)',\n",
       " 'CLS+AP layers from all blocks (attentive)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_order = [col for col in experiment_with_probe_type_order_list if (\"middle & last\" not in col) and (\"quarterly\" not in col) and (\"AP last layer\"!=col)]\n",
    "curr_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a6744ed-4aad-4c43-8d14-a233ca5529df",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_runs = all_runs[all_runs['Experiment'].isin(curr_order)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe2a892-c7da-4039-9613-b88f340a3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mapping = subset_runs[['dataset', 'dataset_fmt', 'dataset_domain']].value_counts().reset_index().set_index('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c6e7b6b-a964-44c8-9766-feb337be5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_values_wrt_to_highest_mean(ds_data, alpha=0.05, metric_col = 'test_lp_bal_acc1'):\n",
    "    best_mean_exp_per_ds = ds_data.groupby(\"Experiment\")[metric_col].mean().idxmax()\n",
    "\n",
    "    pvalues = {best_mean_exp_per_ds: np.nan}\n",
    "    exp1_data = pd.to_numeric(ds_data[ds_data['Experiment'] == best_mean_exp_per_ds][metric_col]).values\n",
    "    assert len(exp1_data)==9\n",
    "    for exp in sorted(ds_data[\"Experiment\"].unique()):\n",
    "        if exp == best_mean_exp_per_ds:\n",
    "            continue\n",
    "        \n",
    "        exp2_data = pd.to_numeric(ds_data[ds_data['Experiment'] == exp][metric_col]).values\n",
    "        if len(exp1_data) != len(exp2_data):\n",
    "            print(f\"\\n!!!Could not compute the statistical test between performances of {best_mean_exp_per_ds} and {exp} for dataset {ds_data.name}, because of mismatching run counts!!!\\n\")\n",
    "            continue\n",
    "\n",
    "        assert len(exp1_data) == len(exp2_data)\n",
    "        \n",
    "        statistic, pval = wilcoxon(exp1_data, exp2_data, alternative='greater')\n",
    "        pvalues[exp] = pval\n",
    "\n",
    "    rejected = {exp: pval < alpha for exp, pval in pvalues.items()}\n",
    "    return dict(pvalues=pvalues, rejected=rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da64153-a9f8-4272-9d11-516a1ded6222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3699506/2396546013.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  res = subset_runs.groupby('dataset').apply(get_p_values_wrt_to_highest_mean)\n"
     ]
    }
   ],
   "source": [
    "res = subset_runs.groupby('dataset').apply(get_p_values_wrt_to_highest_mean)\n",
    "res_df = pd.DataFrame(res.tolist(), index=res.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6357032b-9f6b-40e4-bd90-efa9fb6ac9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset_runs.groupby([\"dataset\", \"Experiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4317e070-f600-4d47-9158-7e827e26d38f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Experiment</th>\n",
       "      <th>CLS last layer</th>\n",
       "      <th>All tokens last layer (attentive)</th>\n",
       "      <th>CLS+AP last layer (linear)</th>\n",
       "      <th>CLS+AP layers from all blocks (linear)</th>\n",
       "      <th>CLS+AP last layer (attentive)</th>\n",
       "      <th>CLS+AP layers from all blocks (attentive)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wds/cars</th>\n",
       "      <td>0.86 ± 0.05</td>\n",
       "      <td>\\textbf{13.65 ± 5.44}</td>\n",
       "      <td>4.03 ± 2.22</td>\n",
       "      <td>13.41 ± 5.37</td>\n",
       "      <td>2.12 ± 2.82</td>\n",
       "      <td>12.62 ± 5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/country211</th>\n",
       "      <td>0.31 ± 0.05</td>\n",
       "      <td>66.31 ± 9.81</td>\n",
       "      <td>5.59 ± 2.81</td>\n",
       "      <td>24.84 ± 8.62</td>\n",
       "      <td>8.62 ± 6.98</td>\n",
       "      <td>\\textbf{48.02 ± 6.04}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/fer2013</th>\n",
       "      <td>0.56 ± 0.03</td>\n",
       "      <td>23.30 ± 6.85</td>\n",
       "      <td>3.40 ± 1.12</td>\n",
       "      <td>11.37 ± 1.59</td>\n",
       "      <td>3.74 ± 1.07</td>\n",
       "      <td>\\textbf{16.47 ± 2.07}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/fgvc_aircraft</th>\n",
       "      <td>0.74 ± 0.09</td>\n",
       "      <td>\\textbf{25.42 ± 8.32}</td>\n",
       "      <td>3.75 ± 3.04</td>\n",
       "      <td>23.58 ± 7.18</td>\n",
       "      <td>3.42 ± 3.98</td>\n",
       "      <td>21.81 ± 8.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/gtsrb</th>\n",
       "      <td>0.84 ± 0.03</td>\n",
       "      <td>\\textbf{15.76 ± 3.13}</td>\n",
       "      <td>5.74 ± 2.03</td>\n",
       "      <td>15.20 ± 2.97</td>\n",
       "      <td>5.83 ± 2.20</td>\n",
       "      <td>15.10 ± 2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/imagenet1k</th>\n",
       "      <td>0.83 ± 0.08</td>\n",
       "      <td>6.41 ± 3.85</td>\n",
       "      <td>\\textbf{1.20 ± 0.78}</td>\n",
       "      <td>7.13 ± 4.23</td>\n",
       "      <td>0.30 ± 0.91</td>\n",
       "      <td>\\textbf{3.89 ± 3.89}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/stl10</th>\n",
       "      <td>\\textbf{0.99 ± 0.00}</td>\n",
       "      <td>\\textbf{0.57 ± 0.45}</td>\n",
       "      <td>\\textbf{0.11 ± 0.34}</td>\n",
       "      <td>\\textbf{0.56 ± 0.42}</td>\n",
       "      <td>\\textbf{0.21 ± 0.22}</td>\n",
       "      <td>\\textbf{0.52 ± 0.44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/voc2007</th>\n",
       "      <td>0.90 ± 0.04</td>\n",
       "      <td>9.40 ± 4.06</td>\n",
       "      <td>\\textbf{2.93 ± 1.51}</td>\n",
       "      <td>\\textbf{7.21 ± 4.17}</td>\n",
       "      <td>\\textbf{3.55 ± 0.96}</td>\n",
       "      <td>\\textbf{9.03 ± 3.76}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/caltech101</th>\n",
       "      <td>0.99 ± 0.01</td>\n",
       "      <td>1.18 ± 0.97</td>\n",
       "      <td>0.72 ± 0.72</td>\n",
       "      <td>1.18 ± 0.97</td>\n",
       "      <td>0.30 ± 0.50</td>\n",
       "      <td>\\textbf{1.18 ± 0.97}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/cifar10</th>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>3.88 ± 2.81</td>\n",
       "      <td>0.73 ± 0.64</td>\n",
       "      <td>2.29 ± 1.70</td>\n",
       "      <td>0.71 ± 0.76</td>\n",
       "      <td>\\textbf{2.67 ± 1.81}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/cifar100</th>\n",
       "      <td>0.84 ± 0.10</td>\n",
       "      <td>15.97 ± 9.55</td>\n",
       "      <td>2.51 ± 1.45</td>\n",
       "      <td>9.72 ± 6.91</td>\n",
       "      <td>2.80 ± 1.56</td>\n",
       "      <td>\\textbf{11.90 ± 6.69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/diabetic_retinopathy</th>\n",
       "      <td>0.44 ± 0.03</td>\n",
       "      <td>28.78 ± 4.98</td>\n",
       "      <td>2.39 ± 0.70</td>\n",
       "      <td>11.05 ± 2.85</td>\n",
       "      <td>1.74 ± 1.26</td>\n",
       "      <td>\\textbf{12.02 ± 3.38}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/dmlab</th>\n",
       "      <td>0.43 ± 0.03</td>\n",
       "      <td>\\textbf{31.50 ± 3.45}</td>\n",
       "      <td>2.25 ± 0.72</td>\n",
       "      <td>11.58 ± 2.24</td>\n",
       "      <td>2.07 ± 1.85</td>\n",
       "      <td>17.40 ± 2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/dtd</th>\n",
       "      <td>0.87 ± 0.06</td>\n",
       "      <td>12.49 ± 5.54</td>\n",
       "      <td>3.84 ± 7.04</td>\n",
       "      <td>\\textbf{12.44 ± 5.52}</td>\n",
       "      <td>8.23 ± 3.91</td>\n",
       "      <td>\\textbf{12.28 ± 5.47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/eurosat</th>\n",
       "      <td>0.90 ± 0.05</td>\n",
       "      <td>10.10 ± 5.42</td>\n",
       "      <td>3.44 ± 1.87</td>\n",
       "      <td>9.32 ± 5.14</td>\n",
       "      <td>3.14 ± 1.24</td>\n",
       "      <td>\\textbf{9.61 ± 5.07}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/flowers</th>\n",
       "      <td>\\textbf{0.99 ± 0.01}</td>\n",
       "      <td>\\textbf{0.60 ± 0.98}</td>\n",
       "      <td>\\textbf{0.45 ± 0.77}</td>\n",
       "      <td>0.60 ± 0.98</td>\n",
       "      <td>\\textbf{-0.25 ± 0.94}</td>\n",
       "      <td>\\textbf{0.60 ± 0.98}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/pcam</th>\n",
       "      <td>0.81 ± 0.03</td>\n",
       "      <td>\\textbf{13.90 ± 2.79}</td>\n",
       "      <td>2.14 ± 0.77</td>\n",
       "      <td>\\textbf{9.02 ± 2.69}</td>\n",
       "      <td>2.83 ± 1.16</td>\n",
       "      <td>11.84 ± 2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/pets</th>\n",
       "      <td>\\textbf{0.97 ± 0.04}</td>\n",
       "      <td>3.12 ± 3.55</td>\n",
       "      <td>\\textbf{0.88 ± 0.92}</td>\n",
       "      <td>3.09 ± 3.55</td>\n",
       "      <td>\\textbf{0.61 ± 0.89}</td>\n",
       "      <td>\\textbf{2.92 ± 3.24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/resisc45</th>\n",
       "      <td>0.88 ± 0.02</td>\n",
       "      <td>12.11 ± 2.11</td>\n",
       "      <td>3.37 ± 0.95</td>\n",
       "      <td>10.99 ± 1.87</td>\n",
       "      <td>3.24 ± 1.12</td>\n",
       "      <td>\\textbf{10.96 ± 1.88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/svhn</th>\n",
       "      <td>0.44 ± 0.04</td>\n",
       "      <td>\\textbf{47.77 ± 5.29}</td>\n",
       "      <td>7.29 ± 2.38</td>\n",
       "      <td>29.23 ± 3.83</td>\n",
       "      <td>6.57 ± 3.70</td>\n",
       "      <td>32.30 ± 4.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Experiment                           CLS last layer  \\\n",
       "dataset                                               \n",
       "wds/cars                                0.86 ± 0.05   \n",
       "wds/country211                          0.31 ± 0.05   \n",
       "wds/fer2013                             0.56 ± 0.03   \n",
       "wds/fgvc_aircraft                       0.74 ± 0.09   \n",
       "wds/gtsrb                               0.84 ± 0.03   \n",
       "wds/imagenet1k                          0.83 ± 0.08   \n",
       "wds/stl10                      \\textbf{0.99 ± 0.00}   \n",
       "wds/voc2007                             0.90 ± 0.04   \n",
       "wds/vtab/caltech101                     0.99 ± 0.01   \n",
       "wds/vtab/cifar10                        0.96 ± 0.03   \n",
       "wds/vtab/cifar100                       0.84 ± 0.10   \n",
       "wds/vtab/diabetic_retinopathy           0.44 ± 0.03   \n",
       "wds/vtab/dmlab                          0.43 ± 0.03   \n",
       "wds/vtab/dtd                            0.87 ± 0.06   \n",
       "wds/vtab/eurosat                        0.90 ± 0.05   \n",
       "wds/vtab/flowers               \\textbf{0.99 ± 0.01}   \n",
       "wds/vtab/pcam                           0.81 ± 0.03   \n",
       "wds/vtab/pets                  \\textbf{0.97 ± 0.04}   \n",
       "wds/vtab/resisc45                       0.88 ± 0.02   \n",
       "wds/vtab/svhn                           0.44 ± 0.04   \n",
       "\n",
       "Experiment                    All tokens last layer (attentive)  \\\n",
       "dataset                                                           \n",
       "wds/cars                                  \\textbf{13.65 ± 5.44}   \n",
       "wds/country211                                     66.31 ± 9.81   \n",
       "wds/fer2013                                        23.30 ± 6.85   \n",
       "wds/fgvc_aircraft                         \\textbf{25.42 ± 8.32}   \n",
       "wds/gtsrb                                 \\textbf{15.76 ± 3.13}   \n",
       "wds/imagenet1k                                      6.41 ± 3.85   \n",
       "wds/stl10                                  \\textbf{0.57 ± 0.45}   \n",
       "wds/voc2007                                         9.40 ± 4.06   \n",
       "wds/vtab/caltech101                                 1.18 ± 0.97   \n",
       "wds/vtab/cifar10                                    3.88 ± 2.81   \n",
       "wds/vtab/cifar100                                  15.97 ± 9.55   \n",
       "wds/vtab/diabetic_retinopathy                      28.78 ± 4.98   \n",
       "wds/vtab/dmlab                            \\textbf{31.50 ± 3.45}   \n",
       "wds/vtab/dtd                                       12.49 ± 5.54   \n",
       "wds/vtab/eurosat                                   10.10 ± 5.42   \n",
       "wds/vtab/flowers                           \\textbf{0.60 ± 0.98}   \n",
       "wds/vtab/pcam                             \\textbf{13.90 ± 2.79}   \n",
       "wds/vtab/pets                                       3.12 ± 3.55   \n",
       "wds/vtab/resisc45                                  12.11 ± 2.11   \n",
       "wds/vtab/svhn                             \\textbf{47.77 ± 5.29}   \n",
       "\n",
       "Experiment                    CLS+AP last layer (linear)  \\\n",
       "dataset                                                    \n",
       "wds/cars                                     4.03 ± 2.22   \n",
       "wds/country211                               5.59 ± 2.81   \n",
       "wds/fer2013                                  3.40 ± 1.12   \n",
       "wds/fgvc_aircraft                            3.75 ± 3.04   \n",
       "wds/gtsrb                                    5.74 ± 2.03   \n",
       "wds/imagenet1k                      \\textbf{1.20 ± 0.78}   \n",
       "wds/stl10                           \\textbf{0.11 ± 0.34}   \n",
       "wds/voc2007                         \\textbf{2.93 ± 1.51}   \n",
       "wds/vtab/caltech101                          0.72 ± 0.72   \n",
       "wds/vtab/cifar10                             0.73 ± 0.64   \n",
       "wds/vtab/cifar100                            2.51 ± 1.45   \n",
       "wds/vtab/diabetic_retinopathy                2.39 ± 0.70   \n",
       "wds/vtab/dmlab                               2.25 ± 0.72   \n",
       "wds/vtab/dtd                                 3.84 ± 7.04   \n",
       "wds/vtab/eurosat                             3.44 ± 1.87   \n",
       "wds/vtab/flowers                    \\textbf{0.45 ± 0.77}   \n",
       "wds/vtab/pcam                                2.14 ± 0.77   \n",
       "wds/vtab/pets                       \\textbf{0.88 ± 0.92}   \n",
       "wds/vtab/resisc45                            3.37 ± 0.95   \n",
       "wds/vtab/svhn                                7.29 ± 2.38   \n",
       "\n",
       "Experiment                    CLS+AP layers from all blocks (linear)  \\\n",
       "dataset                                                                \n",
       "wds/cars                                                13.41 ± 5.37   \n",
       "wds/country211                                          24.84 ± 8.62   \n",
       "wds/fer2013                                             11.37 ± 1.59   \n",
       "wds/fgvc_aircraft                                       23.58 ± 7.18   \n",
       "wds/gtsrb                                               15.20 ± 2.97   \n",
       "wds/imagenet1k                                           7.13 ± 4.23   \n",
       "wds/stl10                                       \\textbf{0.56 ± 0.42}   \n",
       "wds/voc2007                                     \\textbf{7.21 ± 4.17}   \n",
       "wds/vtab/caltech101                                      1.18 ± 0.97   \n",
       "wds/vtab/cifar10                                         2.29 ± 1.70   \n",
       "wds/vtab/cifar100                                        9.72 ± 6.91   \n",
       "wds/vtab/diabetic_retinopathy                           11.05 ± 2.85   \n",
       "wds/vtab/dmlab                                          11.58 ± 2.24   \n",
       "wds/vtab/dtd                                   \\textbf{12.44 ± 5.52}   \n",
       "wds/vtab/eurosat                                         9.32 ± 5.14   \n",
       "wds/vtab/flowers                                         0.60 ± 0.98   \n",
       "wds/vtab/pcam                                   \\textbf{9.02 ± 2.69}   \n",
       "wds/vtab/pets                                            3.09 ± 3.55   \n",
       "wds/vtab/resisc45                                       10.99 ± 1.87   \n",
       "wds/vtab/svhn                                           29.23 ± 3.83   \n",
       "\n",
       "Experiment                    CLS+AP last layer (attentive)  \\\n",
       "dataset                                                       \n",
       "wds/cars                                        2.12 ± 2.82   \n",
       "wds/country211                                  8.62 ± 6.98   \n",
       "wds/fer2013                                     3.74 ± 1.07   \n",
       "wds/fgvc_aircraft                               3.42 ± 3.98   \n",
       "wds/gtsrb                                       5.83 ± 2.20   \n",
       "wds/imagenet1k                                  0.30 ± 0.91   \n",
       "wds/stl10                              \\textbf{0.21 ± 0.22}   \n",
       "wds/voc2007                            \\textbf{3.55 ± 0.96}   \n",
       "wds/vtab/caltech101                             0.30 ± 0.50   \n",
       "wds/vtab/cifar10                                0.71 ± 0.76   \n",
       "wds/vtab/cifar100                               2.80 ± 1.56   \n",
       "wds/vtab/diabetic_retinopathy                   1.74 ± 1.26   \n",
       "wds/vtab/dmlab                                  2.07 ± 1.85   \n",
       "wds/vtab/dtd                                    8.23 ± 3.91   \n",
       "wds/vtab/eurosat                                3.14 ± 1.24   \n",
       "wds/vtab/flowers                      \\textbf{-0.25 ± 0.94}   \n",
       "wds/vtab/pcam                                   2.83 ± 1.16   \n",
       "wds/vtab/pets                          \\textbf{0.61 ± 0.89}   \n",
       "wds/vtab/resisc45                               3.24 ± 1.12   \n",
       "wds/vtab/svhn                                   6.57 ± 3.70   \n",
       "\n",
       "Experiment                    CLS+AP layers from all blocks (attentive)  \n",
       "dataset                                                                  \n",
       "wds/cars                                                   12.62 ± 5.27  \n",
       "wds/country211                                    \\textbf{48.02 ± 6.04}  \n",
       "wds/fer2013                                       \\textbf{16.47 ± 2.07}  \n",
       "wds/fgvc_aircraft                                          21.81 ± 8.30  \n",
       "wds/gtsrb                                                  15.10 ± 2.87  \n",
       "wds/imagenet1k                                     \\textbf{3.89 ± 3.89}  \n",
       "wds/stl10                                          \\textbf{0.52 ± 0.44}  \n",
       "wds/voc2007                                        \\textbf{9.03 ± 3.76}  \n",
       "wds/vtab/caltech101                                \\textbf{1.18 ± 0.97}  \n",
       "wds/vtab/cifar10                                   \\textbf{2.67 ± 1.81}  \n",
       "wds/vtab/cifar100                                 \\textbf{11.90 ± 6.69}  \n",
       "wds/vtab/diabetic_retinopathy                     \\textbf{12.02 ± 3.38}  \n",
       "wds/vtab/dmlab                                             17.40 ± 2.45  \n",
       "wds/vtab/dtd                                      \\textbf{12.28 ± 5.47}  \n",
       "wds/vtab/eurosat                                   \\textbf{9.61 ± 5.07}  \n",
       "wds/vtab/flowers                                   \\textbf{0.60 ± 0.98}  \n",
       "wds/vtab/pcam                                              11.84 ± 2.81  \n",
       "wds/vtab/pets                                      \\textbf{2.92 ± 3.24}  \n",
       "wds/vtab/resisc45                                 \\textbf{10.96 ± 1.88}  \n",
       "wds/vtab/svhn                                              32.30 ± 4.33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs_perf_gain_train_lp_bal_acc1_mod\n",
      "\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "Category & Dataset & CLS last layer & All tokens last layer (attentive) & CLS+AP last layer (linear) & CLS+AP layers from all blocks (linear) & CLS+AP last layer (attentive) & CLS+AP layers from all blocks (attentive) \\\\\n",
      "\\midrule\n",
      "Natural (multi-domain) & STL-10 & \\textbf{0.99 ± 0.00} & \\textbf{0.57 ± 0.45} & \\textbf{0.11 ± 0.34} & \\textbf{0.56 ± 0.42} & \\textbf{0.21 ± 0.22} & \\textbf{0.52 ± 0.44} \\\\\n",
      "Natural (multi-domain) & Caltech-101 & 0.99 ± 0.01 & 1.18 ± 0.97 & 0.72 ± 0.72 & 1.18 ± 0.97 & 0.30 ± 0.50 & \\textbf{1.18 ± 0.97} \\\\\n",
      "Natural (multi-domain) & CIFAR-10 & 0.96 ± 0.03 & 3.88 ± 2.81 & 0.73 ± 0.64 & 2.29 ± 1.70 & 0.71 ± 0.76 & \\textbf{2.67 ± 1.81} \\\\\n",
      "Natural (multi-domain) & ImageNet-1k & 0.83 ± 0.08 & 6.41 ± 3.85 & \\textbf{1.20 ± 0.78} & 7.13 ± 4.23 & 0.30 ± 0.91 & \\textbf{3.89 ± 3.89} \\\\\n",
      "Natural (multi-domain) & PASCAL VOC 2007 & 0.90 ± 0.04 & 9.40 ± 4.06 & \\textbf{2.93 ± 1.51} & \\textbf{7.21 ± 4.17} & \\textbf{3.55 ± 0.96} & \\textbf{9.03 ± 3.76} \\\\\n",
      "Natural (multi-domain) & CIFAR-100 & 0.84 ± 0.10 & 15.97 ± 9.55 & 2.51 ± 1.45 & 9.72 ± 6.91 & 2.80 ± 1.56 & \\textbf{11.90 ± 6.69} \\\\\n",
      "Natural (multi-domain) & Country-211 & 0.31 ± 0.05 & 66.31 ± 9.81 & 5.59 ± 2.81 & 24.84 ± 8.62 & 8.62 ± 6.98 & \\textbf{48.02 ± 6.04} \\\\\n",
      "Natural (single-domain) & Flowers & \\textbf{0.99 ± 0.01} & \\textbf{0.60 ± 0.98} & \\textbf{0.45 ± 0.77} & 0.60 ± 0.98 & \\textbf{-0.25 ± 0.94} & \\textbf{0.60 ± 0.98} \\\\\n",
      "Natural (single-domain) & Pets & \\textbf{0.97 ± 0.04} & 3.12 ± 3.55 & \\textbf{0.88 ± 0.92} & 3.09 ± 3.55 & \\textbf{0.61 ± 0.89} & \\textbf{2.92 ± 3.24} \\\\\n",
      "Natural (single-domain) & Stanford Cars & 0.86 ± 0.05 & \\textbf{13.65 ± 5.44} & 4.03 ± 2.22 & 13.41 ± 5.37 & 2.12 ± 2.82 & 12.62 ± 5.27 \\\\\n",
      "Natural (single-domain) & GTSRB & 0.84 ± 0.03 & \\textbf{15.76 ± 3.13} & 5.74 ± 2.03 & 15.20 ± 2.97 & 5.83 ± 2.20 & 15.10 ± 2.87 \\\\\n",
      "Natural (single-domain) & FGVC Aircraft & 0.74 ± 0.09 & \\textbf{25.42 ± 8.32} & 3.75 ± 3.04 & 23.58 ± 7.18 & 3.42 ± 3.98 & 21.81 ± 8.30 \\\\\n",
      "Natural (single-domain) & SVHN & 0.44 ± 0.04 & \\textbf{47.77 ± 5.29} & 7.29 ± 2.38 & 29.23 ± 3.83 & 6.57 ± 3.70 & 32.30 ± 4.33 \\\\\n",
      "Specialized & EuroSAT & 0.90 ± 0.05 & 10.10 ± 5.42 & 3.44 ± 1.87 & 9.32 ± 5.14 & 3.14 ± 1.24 & \\textbf{9.61 ± 5.07} \\\\\n",
      "Specialized & RESISC45 & 0.88 ± 0.02 & 12.11 ± 2.11 & 3.37 ± 0.95 & 10.99 ± 1.87 & 3.24 ± 1.12 & \\textbf{10.96 ± 1.88} \\\\\n",
      "Specialized & PCAM & 0.81 ± 0.03 & \\textbf{13.90 ± 2.79} & 2.14 ± 0.77 & \\textbf{9.02 ± 2.69} & 2.83 ± 1.16 & 11.84 ± 2.81 \\\\\n",
      "Specialized & Diabetic Retinopathy & 0.44 ± 0.03 & 28.78 ± 4.98 & 2.39 ± 0.70 & 11.05 ± 2.85 & 1.74 ± 1.26 & \\textbf{12.02 ± 3.38} \\\\\n",
      "Structured & DTD & 0.87 ± 0.06 & 12.49 ± 5.54 & 3.84 ± 7.04 & \\textbf{12.44 ± 5.52} & 8.23 ± 3.91 & \\textbf{12.28 ± 5.47} \\\\\n",
      "Structured & FER2013 & 0.56 ± 0.03 & 23.30 ± 6.85 & 3.40 ± 1.12 & 11.37 ± 1.59 & 3.74 ± 1.07 & \\textbf{16.47 ± 2.07} \\\\\n",
      "Structured & Dmlab & 0.43 ± 0.03 & \\textbf{31.50 ± 3.45} & 2.25 ± 0.72 & 11.58 ± 2.24 & 2.07 ± 1.85 & 17.40 ± 2.45 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Experiment</th>\n",
       "      <th>CLS last layer</th>\n",
       "      <th>All tokens last layer (attentive)</th>\n",
       "      <th>CLS+AP last layer (linear)</th>\n",
       "      <th>CLS+AP layers from all blocks (linear)</th>\n",
       "      <th>CLS+AP last layer (attentive)</th>\n",
       "      <th>CLS+AP layers from all blocks (attentive)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wds/cars</th>\n",
       "      <td>77.81 ± 10.65</td>\n",
       "      <td>\\textbf{8.97 ± 5.22}</td>\n",
       "      <td>0.50 ± 1.07</td>\n",
       "      <td>-0.86 ± 3.76</td>\n",
       "      <td>1.97 ± 1.95</td>\n",
       "      <td>6.35 ± 3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/country211</th>\n",
       "      <td>21.48 ± 6.35</td>\n",
       "      <td>-0.83 ± 1.66</td>\n",
       "      <td>1.18 ± 0.54</td>\n",
       "      <td>3.26 ± 1.05</td>\n",
       "      <td>1.35 ± 0.65</td>\n",
       "      <td>\\textbf{4.96 ± 1.37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/fer2013</th>\n",
       "      <td>59.08 ± 4.61</td>\n",
       "      <td>7.74 ± 2.15</td>\n",
       "      <td>2.18 ± 1.05</td>\n",
       "      <td>6.25 ± 1.19</td>\n",
       "      <td>3.61 ± 1.13</td>\n",
       "      <td>\\textbf{10.05 ± 1.76}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/fgvc_aircraft</th>\n",
       "      <td>55.69 ± 12.18</td>\n",
       "      <td>\\textbf{9.27 ± 4.37}</td>\n",
       "      <td>-0.96 ± 2.22</td>\n",
       "      <td>-1.62 ± 5.01</td>\n",
       "      <td>1.84 ± 2.09</td>\n",
       "      <td>6.43 ± 3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/gtsrb</th>\n",
       "      <td>71.51 ± 7.46</td>\n",
       "      <td>\\textbf{18.02 ± 6.37}</td>\n",
       "      <td>4.23 ± 2.60</td>\n",
       "      <td>8.76 ± 4.20</td>\n",
       "      <td>4.69 ± 2.41</td>\n",
       "      <td>13.47 ± 4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/imagenet1k</th>\n",
       "      <td>81.40 ± 4.49</td>\n",
       "      <td>0.85 ± 1.43</td>\n",
       "      <td>\\textbf{0.33 ± 0.46}</td>\n",
       "      <td>0.99 ± 1.75</td>\n",
       "      <td>0.15 ± 0.62</td>\n",
       "      <td>\\textbf{1.24 ± 1.62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/stl10</th>\n",
       "      <td>\\textbf{99.29 ± 0.51}</td>\n",
       "      <td>\\textbf{0.01 ± 0.16}</td>\n",
       "      <td>\\textbf{-0.01 ± 0.12}</td>\n",
       "      <td>\\textbf{0.03 ± 0.10}</td>\n",
       "      <td>\\textbf{0.03 ± 0.08}</td>\n",
       "      <td>\\textbf{0.04 ± 0.17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/voc2007</th>\n",
       "      <td>87.82 ± 2.31</td>\n",
       "      <td>-0.22 ± 1.24</td>\n",
       "      <td>\\textbf{1.38 ± 0.49}</td>\n",
       "      <td>\\textbf{1.46 ± 0.99}</td>\n",
       "      <td>\\textbf{1.19 ± 0.88}</td>\n",
       "      <td>\\textbf{1.24 ± 0.89}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/caltech101</th>\n",
       "      <td>95.57 ± 1.40</td>\n",
       "      <td>0.23 ± 0.52</td>\n",
       "      <td>0.43 ± 0.41</td>\n",
       "      <td>0.36 ± 0.63</td>\n",
       "      <td>0.09 ± 0.42</td>\n",
       "      <td>\\textbf{0.88 ± 0.77}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/cifar10</th>\n",
       "      <td>96.91 ± 1.93</td>\n",
       "      <td>0.42 ± 0.58</td>\n",
       "      <td>0.08 ± 0.11</td>\n",
       "      <td>0.61 ± 0.71</td>\n",
       "      <td>0.19 ± 0.29</td>\n",
       "      <td>\\textbf{0.77 ± 0.79}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/cifar100</th>\n",
       "      <td>85.45 ± 5.71</td>\n",
       "      <td>1.73 ± 1.33</td>\n",
       "      <td>0.61 ± 0.21</td>\n",
       "      <td>2.76 ± 2.48</td>\n",
       "      <td>0.87 ± 0.56</td>\n",
       "      <td>\\textbf{3.33 ± 2.75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/diabetic_retinopathy</th>\n",
       "      <td>45.80 ± 2.46</td>\n",
       "      <td>1.94 ± 1.90</td>\n",
       "      <td>1.55 ± 0.44</td>\n",
       "      <td>5.92 ± 2.03</td>\n",
       "      <td>1.86 ± 0.77</td>\n",
       "      <td>\\textbf{6.86 ± 2.00}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/dmlab</th>\n",
       "      <td>44.91 ± 3.49</td>\n",
       "      <td>\\textbf{13.69 ± 2.77}</td>\n",
       "      <td>1.81 ± 0.45</td>\n",
       "      <td>7.92 ± 1.95</td>\n",
       "      <td>2.61 ± 1.65</td>\n",
       "      <td>10.68 ± 2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/dtd</th>\n",
       "      <td>75.99 ± 3.47</td>\n",
       "      <td>1.41 ± 2.19</td>\n",
       "      <td>1.18 ± 1.76</td>\n",
       "      <td>\\textbf{4.04 ± 2.19}</td>\n",
       "      <td>2.53 ± 1.67</td>\n",
       "      <td>\\textbf{4.05 ± 1.92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/eurosat</th>\n",
       "      <td>93.89 ± 2.52</td>\n",
       "      <td>3.38 ± 2.18</td>\n",
       "      <td>1.65 ± 1.17</td>\n",
       "      <td>4.08 ± 2.48</td>\n",
       "      <td>1.82 ± 1.22</td>\n",
       "      <td>\\textbf{4.37 ± 2.41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/flowers</th>\n",
       "      <td>\\textbf{98.03 ± 2.60}</td>\n",
       "      <td>\\textbf{0.41 ± 0.93}</td>\n",
       "      <td>\\textbf{0.40 ± 0.75}</td>\n",
       "      <td>-0.25 ± 0.57</td>\n",
       "      <td>\\textbf{0.06 ± 0.76}</td>\n",
       "      <td>\\textbf{0.46 ± 0.97}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/pcam</th>\n",
       "      <td>82.04 ± 2.15</td>\n",
       "      <td>\\textbf{5.03 ± 1.47}</td>\n",
       "      <td>1.38 ± 0.56</td>\n",
       "      <td>\\textbf{5.32 ± 1.62}</td>\n",
       "      <td>2.66 ± 1.33</td>\n",
       "      <td>2.85 ± 2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/pets</th>\n",
       "      <td>\\textbf{93.98 ± 2.36}</td>\n",
       "      <td>-0.23 ± 0.83</td>\n",
       "      <td>\\textbf{-0.05 ± 0.41}</td>\n",
       "      <td>-2.01 ± 1.04</td>\n",
       "      <td>\\textbf{0.12 ± 0.53}</td>\n",
       "      <td>\\textbf{0.29 ± 0.76}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/resisc45</th>\n",
       "      <td>90.45 ± 1.69</td>\n",
       "      <td>4.07 ± 1.05</td>\n",
       "      <td>1.32 ± 0.74</td>\n",
       "      <td>4.53 ± 0.99</td>\n",
       "      <td>1.82 ± 0.59</td>\n",
       "      <td>\\textbf{5.23 ± 1.10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wds/vtab/svhn</th>\n",
       "      <td>56.06 ± 5.91</td>\n",
       "      <td>\\textbf{30.31 ± 5.08}</td>\n",
       "      <td>6.94 ± 2.59</td>\n",
       "      <td>24.40 ± 4.41</td>\n",
       "      <td>7.39 ± 3.70</td>\n",
       "      <td>27.25 ± 4.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Experiment                            CLS last layer  \\\n",
       "dataset                                                \n",
       "wds/cars                               77.81 ± 10.65   \n",
       "wds/country211                          21.48 ± 6.35   \n",
       "wds/fer2013                             59.08 ± 4.61   \n",
       "wds/fgvc_aircraft                      55.69 ± 12.18   \n",
       "wds/gtsrb                               71.51 ± 7.46   \n",
       "wds/imagenet1k                          81.40 ± 4.49   \n",
       "wds/stl10                      \\textbf{99.29 ± 0.51}   \n",
       "wds/voc2007                             87.82 ± 2.31   \n",
       "wds/vtab/caltech101                     95.57 ± 1.40   \n",
       "wds/vtab/cifar10                        96.91 ± 1.93   \n",
       "wds/vtab/cifar100                       85.45 ± 5.71   \n",
       "wds/vtab/diabetic_retinopathy           45.80 ± 2.46   \n",
       "wds/vtab/dmlab                          44.91 ± 3.49   \n",
       "wds/vtab/dtd                            75.99 ± 3.47   \n",
       "wds/vtab/eurosat                        93.89 ± 2.52   \n",
       "wds/vtab/flowers               \\textbf{98.03 ± 2.60}   \n",
       "wds/vtab/pcam                           82.04 ± 2.15   \n",
       "wds/vtab/pets                  \\textbf{93.98 ± 2.36}   \n",
       "wds/vtab/resisc45                       90.45 ± 1.69   \n",
       "wds/vtab/svhn                           56.06 ± 5.91   \n",
       "\n",
       "Experiment                    All tokens last layer (attentive)  \\\n",
       "dataset                                                           \n",
       "wds/cars                                   \\textbf{8.97 ± 5.22}   \n",
       "wds/country211                                     -0.83 ± 1.66   \n",
       "wds/fer2013                                         7.74 ± 2.15   \n",
       "wds/fgvc_aircraft                          \\textbf{9.27 ± 4.37}   \n",
       "wds/gtsrb                                 \\textbf{18.02 ± 6.37}   \n",
       "wds/imagenet1k                                      0.85 ± 1.43   \n",
       "wds/stl10                                  \\textbf{0.01 ± 0.16}   \n",
       "wds/voc2007                                        -0.22 ± 1.24   \n",
       "wds/vtab/caltech101                                 0.23 ± 0.52   \n",
       "wds/vtab/cifar10                                    0.42 ± 0.58   \n",
       "wds/vtab/cifar100                                   1.73 ± 1.33   \n",
       "wds/vtab/diabetic_retinopathy                       1.94 ± 1.90   \n",
       "wds/vtab/dmlab                            \\textbf{13.69 ± 2.77}   \n",
       "wds/vtab/dtd                                        1.41 ± 2.19   \n",
       "wds/vtab/eurosat                                    3.38 ± 2.18   \n",
       "wds/vtab/flowers                           \\textbf{0.41 ± 0.93}   \n",
       "wds/vtab/pcam                              \\textbf{5.03 ± 1.47}   \n",
       "wds/vtab/pets                                      -0.23 ± 0.83   \n",
       "wds/vtab/resisc45                                   4.07 ± 1.05   \n",
       "wds/vtab/svhn                             \\textbf{30.31 ± 5.08}   \n",
       "\n",
       "Experiment                    CLS+AP last layer (linear)  \\\n",
       "dataset                                                    \n",
       "wds/cars                                     0.50 ± 1.07   \n",
       "wds/country211                               1.18 ± 0.54   \n",
       "wds/fer2013                                  2.18 ± 1.05   \n",
       "wds/fgvc_aircraft                           -0.96 ± 2.22   \n",
       "wds/gtsrb                                    4.23 ± 2.60   \n",
       "wds/imagenet1k                      \\textbf{0.33 ± 0.46}   \n",
       "wds/stl10                          \\textbf{-0.01 ± 0.12}   \n",
       "wds/voc2007                         \\textbf{1.38 ± 0.49}   \n",
       "wds/vtab/caltech101                          0.43 ± 0.41   \n",
       "wds/vtab/cifar10                             0.08 ± 0.11   \n",
       "wds/vtab/cifar100                            0.61 ± 0.21   \n",
       "wds/vtab/diabetic_retinopathy                1.55 ± 0.44   \n",
       "wds/vtab/dmlab                               1.81 ± 0.45   \n",
       "wds/vtab/dtd                                 1.18 ± 1.76   \n",
       "wds/vtab/eurosat                             1.65 ± 1.17   \n",
       "wds/vtab/flowers                    \\textbf{0.40 ± 0.75}   \n",
       "wds/vtab/pcam                                1.38 ± 0.56   \n",
       "wds/vtab/pets                      \\textbf{-0.05 ± 0.41}   \n",
       "wds/vtab/resisc45                            1.32 ± 0.74   \n",
       "wds/vtab/svhn                                6.94 ± 2.59   \n",
       "\n",
       "Experiment                    CLS+AP layers from all blocks (linear)  \\\n",
       "dataset                                                                \n",
       "wds/cars                                                -0.86 ± 3.76   \n",
       "wds/country211                                           3.26 ± 1.05   \n",
       "wds/fer2013                                              6.25 ± 1.19   \n",
       "wds/fgvc_aircraft                                       -1.62 ± 5.01   \n",
       "wds/gtsrb                                                8.76 ± 4.20   \n",
       "wds/imagenet1k                                           0.99 ± 1.75   \n",
       "wds/stl10                                       \\textbf{0.03 ± 0.10}   \n",
       "wds/voc2007                                     \\textbf{1.46 ± 0.99}   \n",
       "wds/vtab/caltech101                                      0.36 ± 0.63   \n",
       "wds/vtab/cifar10                                         0.61 ± 0.71   \n",
       "wds/vtab/cifar100                                        2.76 ± 2.48   \n",
       "wds/vtab/diabetic_retinopathy                            5.92 ± 2.03   \n",
       "wds/vtab/dmlab                                           7.92 ± 1.95   \n",
       "wds/vtab/dtd                                    \\textbf{4.04 ± 2.19}   \n",
       "wds/vtab/eurosat                                         4.08 ± 2.48   \n",
       "wds/vtab/flowers                                        -0.25 ± 0.57   \n",
       "wds/vtab/pcam                                   \\textbf{5.32 ± 1.62}   \n",
       "wds/vtab/pets                                           -2.01 ± 1.04   \n",
       "wds/vtab/resisc45                                        4.53 ± 0.99   \n",
       "wds/vtab/svhn                                           24.40 ± 4.41   \n",
       "\n",
       "Experiment                    CLS+AP last layer (attentive)  \\\n",
       "dataset                                                       \n",
       "wds/cars                                        1.97 ± 1.95   \n",
       "wds/country211                                  1.35 ± 0.65   \n",
       "wds/fer2013                                     3.61 ± 1.13   \n",
       "wds/fgvc_aircraft                               1.84 ± 2.09   \n",
       "wds/gtsrb                                       4.69 ± 2.41   \n",
       "wds/imagenet1k                                  0.15 ± 0.62   \n",
       "wds/stl10                              \\textbf{0.03 ± 0.08}   \n",
       "wds/voc2007                            \\textbf{1.19 ± 0.88}   \n",
       "wds/vtab/caltech101                             0.09 ± 0.42   \n",
       "wds/vtab/cifar10                                0.19 ± 0.29   \n",
       "wds/vtab/cifar100                               0.87 ± 0.56   \n",
       "wds/vtab/diabetic_retinopathy                   1.86 ± 0.77   \n",
       "wds/vtab/dmlab                                  2.61 ± 1.65   \n",
       "wds/vtab/dtd                                    2.53 ± 1.67   \n",
       "wds/vtab/eurosat                                1.82 ± 1.22   \n",
       "wds/vtab/flowers                       \\textbf{0.06 ± 0.76}   \n",
       "wds/vtab/pcam                                   2.66 ± 1.33   \n",
       "wds/vtab/pets                          \\textbf{0.12 ± 0.53}   \n",
       "wds/vtab/resisc45                               1.82 ± 0.59   \n",
       "wds/vtab/svhn                                   7.39 ± 3.70   \n",
       "\n",
       "Experiment                    CLS+AP layers from all blocks (attentive)  \n",
       "dataset                                                                  \n",
       "wds/cars                                                    6.35 ± 3.71  \n",
       "wds/country211                                     \\textbf{4.96 ± 1.37}  \n",
       "wds/fer2013                                       \\textbf{10.05 ± 1.76}  \n",
       "wds/fgvc_aircraft                                           6.43 ± 3.25  \n",
       "wds/gtsrb                                                  13.47 ± 4.92  \n",
       "wds/imagenet1k                                     \\textbf{1.24 ± 1.62}  \n",
       "wds/stl10                                          \\textbf{0.04 ± 0.17}  \n",
       "wds/voc2007                                        \\textbf{1.24 ± 0.89}  \n",
       "wds/vtab/caltech101                                \\textbf{0.88 ± 0.77}  \n",
       "wds/vtab/cifar10                                   \\textbf{0.77 ± 0.79}  \n",
       "wds/vtab/cifar100                                  \\textbf{3.33 ± 2.75}  \n",
       "wds/vtab/diabetic_retinopathy                      \\textbf{6.86 ± 2.00}  \n",
       "wds/vtab/dmlab                                             10.68 ± 2.78  \n",
       "wds/vtab/dtd                                       \\textbf{4.05 ± 1.92}  \n",
       "wds/vtab/eurosat                                   \\textbf{4.37 ± 2.41}  \n",
       "wds/vtab/flowers                                   \\textbf{0.46 ± 0.97}  \n",
       "wds/vtab/pcam                                               2.85 ± 2.53  \n",
       "wds/vtab/pets                                      \\textbf{0.29 ± 0.76}  \n",
       "wds/vtab/resisc45                                  \\textbf{5.23 ± 1.10}  \n",
       "wds/vtab/svhn                                              27.25 ± 4.24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs_perf_gain_test_lp_bal_acc1_mod\n",
      "\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "Category & Dataset & CLS last layer & All tokens last layer (attentive) & CLS+AP last layer (linear) & CLS+AP layers from all blocks (linear) & CLS+AP last layer (attentive) & CLS+AP layers from all blocks (attentive) \\\\\n",
      "\\midrule\n",
      "Natural (multi-domain) & STL-10 & \\textbf{99.29 ± 0.51} & \\textbf{0.01 ± 0.16} & \\textbf{-0.01 ± 0.12} & \\textbf{0.03 ± 0.10} & \\textbf{0.03 ± 0.08} & \\textbf{0.04 ± 0.17} \\\\\n",
      "Natural (multi-domain) & CIFAR-10 & 96.91 ± 1.93 & 0.42 ± 0.58 & 0.08 ± 0.11 & 0.61 ± 0.71 & 0.19 ± 0.29 & \\textbf{0.77 ± 0.79} \\\\\n",
      "Natural (multi-domain) & Caltech-101 & 95.57 ± 1.40 & 0.23 ± 0.52 & 0.43 ± 0.41 & 0.36 ± 0.63 & 0.09 ± 0.42 & \\textbf{0.88 ± 0.77} \\\\\n",
      "Natural (multi-domain) & PASCAL VOC 2007 & 87.82 ± 2.31 & -0.22 ± 1.24 & \\textbf{1.38 ± 0.49} & \\textbf{1.46 ± 0.99} & \\textbf{1.19 ± 0.88} & \\textbf{1.24 ± 0.89} \\\\\n",
      "Natural (multi-domain) & ImageNet-1k & 81.40 ± 4.49 & 0.85 ± 1.43 & \\textbf{0.33 ± 0.46} & 0.99 ± 1.75 & 0.15 ± 0.62 & \\textbf{1.24 ± 1.62} \\\\\n",
      "Natural (multi-domain) & CIFAR-100 & 85.45 ± 5.71 & 1.73 ± 1.33 & 0.61 ± 0.21 & 2.76 ± 2.48 & 0.87 ± 0.56 & \\textbf{3.33 ± 2.75} \\\\\n",
      "Natural (multi-domain) & Country-211 & 21.48 ± 6.35 & -0.83 ± 1.66 & 1.18 ± 0.54 & 3.26 ± 1.05 & 1.35 ± 0.65 & \\textbf{4.96 ± 1.37} \\\\\n",
      "Natural (single-domain) & Pets & \\textbf{93.98 ± 2.36} & -0.23 ± 0.83 & \\textbf{-0.05 ± 0.41} & -2.01 ± 1.04 & \\textbf{0.12 ± 0.53} & \\textbf{0.29 ± 0.76} \\\\\n",
      "Natural (single-domain) & Flowers & \\textbf{98.03 ± 2.60} & \\textbf{0.41 ± 0.93} & \\textbf{0.40 ± 0.75} & -0.25 ± 0.57 & \\textbf{0.06 ± 0.76} & \\textbf{0.46 ± 0.97} \\\\\n",
      "Natural (single-domain) & Stanford Cars & 77.81 ± 10.65 & \\textbf{8.97 ± 5.22} & 0.50 ± 1.07 & -0.86 ± 3.76 & 1.97 ± 1.95 & 6.35 ± 3.71 \\\\\n",
      "Natural (single-domain) & FGVC Aircraft & 55.69 ± 12.18 & \\textbf{9.27 ± 4.37} & -0.96 ± 2.22 & -1.62 ± 5.01 & 1.84 ± 2.09 & 6.43 ± 3.25 \\\\\n",
      "Natural (single-domain) & GTSRB & 71.51 ± 7.46 & \\textbf{18.02 ± 6.37} & 4.23 ± 2.60 & 8.76 ± 4.20 & 4.69 ± 2.41 & 13.47 ± 4.92 \\\\\n",
      "Natural (single-domain) & SVHN & 56.06 ± 5.91 & \\textbf{30.31 ± 5.08} & 6.94 ± 2.59 & 24.40 ± 4.41 & 7.39 ± 3.70 & 27.25 ± 4.24 \\\\\n",
      "Specialized & PCAM & 82.04 ± 2.15 & \\textbf{5.03 ± 1.47} & 1.38 ± 0.56 & \\textbf{5.32 ± 1.62} & 2.66 ± 1.33 & 2.85 ± 2.53 \\\\\n",
      "Specialized & EuroSAT & 93.89 ± 2.52 & 3.38 ± 2.18 & 1.65 ± 1.17 & 4.08 ± 2.48 & 1.82 ± 1.22 & \\textbf{4.37 ± 2.41} \\\\\n",
      "Specialized & RESISC45 & 90.45 ± 1.69 & 4.07 ± 1.05 & 1.32 ± 0.74 & 4.53 ± 0.99 & 1.82 ± 0.59 & \\textbf{5.23 ± 1.10} \\\\\n",
      "Specialized & Diabetic Retinopathy & 45.80 ± 2.46 & 1.94 ± 1.90 & 1.55 ± 0.44 & 5.92 ± 2.03 & 1.86 ± 0.77 & \\textbf{6.86 ± 2.00} \\\\\n",
      "Structured & DTD & 75.99 ± 3.47 & 1.41 ± 2.19 & 1.18 ± 1.76 & \\textbf{4.04 ± 2.19} & 2.53 ± 1.67 & \\textbf{4.05 ± 1.92} \\\\\n",
      "Structured & FER2013 & 59.08 ± 4.61 & 7.74 ± 2.15 & 2.18 ± 1.05 & 6.25 ± 1.19 & 3.61 ± 1.13 & \\textbf{10.05 ± 1.76} \\\\\n",
      "Structured & Dmlab & 44.91 ± 3.49 & \\textbf{13.69 ± 2.77} & 1.81 ± 0.45 & 7.92 ± 1.95 & 2.61 ± 1.65 & 10.68 ± 2.78 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric_col in metrics_cols:\n",
    "    aggr_data = grouped_data[metric_col].agg([\"mean\", \"std\"]).reset_index()\n",
    "    \n",
    "    mean_pivot = pd.pivot(\n",
    "        aggr_data,\n",
    "        index='dataset',\n",
    "        columns=\"Experiment\", \n",
    "        values=\"mean\"\n",
    "    ).loc[:, curr_order]\n",
    "    \n",
    "    formatted_data = []\n",
    "    for idx, row in aggr_data.iterrows():\n",
    "        dataset = row['dataset']\n",
    "        exp = row['Experiment']\n",
    "        if dataset in mean_pivot.index and exp in mean_pivot.columns:\n",
    "            try:\n",
    "                is_significant = res_df.loc[dataset, 'rejected'][exp]\n",
    "            except:\n",
    "                is_significant = False\n",
    "            formatted = format_if_is_bold(row['mean'], row['std'], is_significant)\n",
    "            formatted_data.append({\n",
    "                'dataset': dataset,\n",
    "                'Experiment': exp,\n",
    "                'mean_std': formatted\n",
    "            }) \n",
    "    \n",
    "    formatted_df = pd.DataFrame(formatted_data)\n",
    "    pivoted_aggr_data = pd.pivot(\n",
    "        formatted_df,\n",
    "        index='dataset',\n",
    "        columns=\"Experiment\",\n",
    "        values=\"mean_std\"\n",
    "    )\n",
    "    \n",
    "    pivoted_aggr_data = pivoted_aggr_data.loc[:, curr_order]\n",
    "    display(pivoted_aggr_data)\n",
    "    pivoted_aggr_data = pivoted_aggr_data.sort_values('CLS+AP layers from all blocks (attentive)', \n",
    "                                                      key=lambda x: x.apply(lambda val: float(val.split('±')[0].split('{')[-1].strip())))\n",
    "    \n",
    "    pivoted_aggr_data.index.name = None\n",
    "    pivoted_aggr_data.columns.name = None\n",
    "    pivoted_aggr_data = pivoted_aggr_data.reset_index(names='Dataset')\n",
    "    pivoted_aggr_data.insert(0, 'Category', ds_mapping.loc[pivoted_aggr_data[\"Dataset\"].tolist(), 'dataset_domain'].reset_index(drop=True))\n",
    "    pivoted_aggr_data['Dataset'] = ds_mapping.loc[pivoted_aggr_data[\"Dataset\"].tolist(), 'dataset_fmt'].reset_index(drop=True)\n",
    "\n",
    "    pivoted_aggr_data = pivoted_aggr_data.sort_values('Category', kind='stable')\n",
    "\n",
    "    latex_version_pivoted_aggr_data = pivoted_aggr_data.to_latex(escape=False, index=False)\n",
    "\n",
    "    if SAVE:\n",
    "        filename = base_storing_path / 'tables_for_per_model_size_n_dataset_perf_gain' / f\"{metric_col}_aggr_over_models_table_with_test_v2.tex\"  # Creates filename based on metric_col\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(latex_version_pivoted_aggr_data)\n",
    "        print(f\"Stored latex table at {filename.parts[-4:]=}\")\n",
    "\n",
    "    else:\n",
    "        print(metric_col)\n",
    "        print()\n",
    "        print(latex_version_pivoted_aggr_data)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc47a3-bf25-43b4-bed2-7f886a411bc4",
   "metadata": {},
   "source": [
    "### Table version with highest median bold, second highest underline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce2ef7f5-9004-40c0-bde1-7b9a511bafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_latex(mean_val, std_val, row_means):\n",
    "    formatted = f\"{mean_val:.2f} ± {std_val:.2f}\"\n",
    "    \n",
    "    sorted_means =sorted(row_means, reverse=True)\n",
    "    if mean_val not in sorted_means:\n",
    "        return formatted\n",
    "        \n",
    "    rank = sorted_means.index(mean_val) + 1\n",
    "\n",
    "    if rank == 1:\n",
    "        return f\"\\\\textbf{{{formatted}}}\"\n",
    "    elif rank == 2:\n",
    "        return f\"\\\\underline{{{formatted}}}\"\n",
    "    else:\n",
    "        return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1673a76-45f3-42d1-b3a3-99e0e461ff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs_perf_gain_train_lp_bal_acc1_mod\n",
      "\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "Category & Dataset & CLS last layer & All tokens last layer (attentive) & CLS+AP last layer (linear) & CLS+AP layers from all blocks (linear) & CLS+AP last layer (attentive) & CLS+AP layers from all blocks (attentive) \\\\\n",
      "\\midrule\n",
      "Natural (multi-domain) & STL-10 & 0.99 ± 0.00 & \\textbf{0.57 ± 0.45} & 0.11 ± 0.34 & \\underline{0.56 ± 0.42} & 0.21 ± 0.22 & 0.52 ± 0.44 \\\\\n",
      "Natural (multi-domain) & Caltech-101 & 0.99 ± 0.01 & \\textbf{1.18 ± 0.97} & 0.72 ± 0.72 & \\textbf{1.18 ± 0.97} & 0.30 ± 0.50 & \\textbf{1.18 ± 0.97} \\\\\n",
      "Natural (multi-domain) & CIFAR-10 & 0.96 ± 0.03 & \\textbf{3.88 ± 2.81} & 0.73 ± 0.64 & 2.29 ± 1.70 & 0.71 ± 0.76 & \\underline{2.67 ± 1.81} \\\\\n",
      "Natural (multi-domain) & ImageNet-1k & 0.83 ± 0.08 & \\underline{6.41 ± 3.85} & 1.20 ± 0.78 & \\textbf{7.13 ± 4.23} & 0.30 ± 0.91 & 3.89 ± 3.89 \\\\\n",
      "Natural (multi-domain) & PASCAL VOC 2007 & 0.90 ± 0.04 & \\textbf{9.40 ± 4.06} & 2.93 ± 1.51 & 7.21 ± 4.17 & 3.55 ± 0.96 & \\underline{9.03 ± 3.76} \\\\\n",
      "Natural (multi-domain) & CIFAR-100 & 0.84 ± 0.10 & \\textbf{15.97 ± 9.55} & 2.51 ± 1.45 & 9.72 ± 6.91 & 2.80 ± 1.56 & \\underline{11.90 ± 6.69} \\\\\n",
      "Natural (multi-domain) & Country-211 & 0.31 ± 0.05 & \\textbf{66.31 ± 9.81} & 5.59 ± 2.81 & 24.84 ± 8.62 & 8.62 ± 6.98 & \\underline{48.02 ± 6.04} \\\\\n",
      "Natural (single-domain) & Flowers & 0.99 ± 0.01 & \\textbf{0.60 ± 0.98} & 0.45 ± 0.77 & \\textbf{0.60 ± 0.98} & -0.25 ± 0.94 & \\textbf{0.60 ± 0.98} \\\\\n",
      "Natural (single-domain) & Pets & 0.97 ± 0.04 & \\textbf{3.12 ± 3.55} & 0.88 ± 0.92 & \\underline{3.09 ± 3.55} & 0.61 ± 0.89 & 2.92 ± 3.24 \\\\\n",
      "Natural (single-domain) & Stanford Cars & 0.86 ± 0.05 & \\textbf{13.65 ± 5.44} & 4.03 ± 2.22 & \\underline{13.41 ± 5.37} & 2.12 ± 2.82 & 12.62 ± 5.27 \\\\\n",
      "Natural (single-domain) & GTSRB & 0.84 ± 0.03 & \\textbf{15.76 ± 3.13} & 5.74 ± 2.03 & \\underline{15.20 ± 2.97} & 5.83 ± 2.20 & 15.10 ± 2.87 \\\\\n",
      "Natural (single-domain) & FGVC Aircraft & 0.74 ± 0.09 & \\textbf{25.42 ± 8.32} & 3.75 ± 3.04 & \\underline{23.58 ± 7.18} & 3.42 ± 3.98 & 21.81 ± 8.30 \\\\\n",
      "Natural (single-domain) & SVHN & 0.44 ± 0.04 & \\textbf{47.77 ± 5.29} & 7.29 ± 2.38 & 29.23 ± 3.83 & 6.57 ± 3.70 & \\underline{32.30 ± 4.33} \\\\\n",
      "Specialized & EuroSAT & 0.90 ± 0.05 & \\textbf{10.10 ± 5.42} & 3.44 ± 1.87 & 9.32 ± 5.14 & 3.14 ± 1.24 & \\underline{9.61 ± 5.07} \\\\\n",
      "Specialized & RESISC45 & 0.88 ± 0.02 & \\textbf{12.11 ± 2.11} & 3.37 ± 0.95 & \\underline{10.99 ± 1.87} & 3.24 ± 1.12 & 10.96 ± 1.88 \\\\\n",
      "Specialized & PCAM & 0.81 ± 0.03 & \\textbf{13.90 ± 2.79} & 2.14 ± 0.77 & 9.02 ± 2.69 & 2.83 ± 1.16 & \\underline{11.84 ± 2.81} \\\\\n",
      "Specialized & Diabetic Retinopathy & 0.44 ± 0.03 & \\textbf{28.78 ± 4.98} & 2.39 ± 0.70 & 11.05 ± 2.85 & 1.74 ± 1.26 & \\underline{12.02 ± 3.38} \\\\\n",
      "Structured & DTD & 0.87 ± 0.06 & \\textbf{12.49 ± 5.54} & 3.84 ± 7.04 & \\underline{12.44 ± 5.52} & 8.23 ± 3.91 & 12.28 ± 5.47 \\\\\n",
      "Structured & FER2013 & 0.56 ± 0.03 & \\textbf{23.30 ± 6.85} & 3.40 ± 1.12 & 11.37 ± 1.59 & 3.74 ± 1.07 & \\underline{16.47 ± 2.07} \\\\\n",
      "Structured & Dmlab & 0.43 ± 0.03 & \\textbf{31.50 ± 3.45} & 2.25 ± 0.72 & 11.58 ± 2.24 & 2.07 ± 1.85 & \\underline{17.40 ± 2.45} \\\\\n",
      "NaN & NaN & NaN & 1.150000 & 4.400000 & 2.450000 & 4.600000 & 2.400000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "abs_perf_gain_test_lp_bal_acc1_mod\n",
      "\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "Category & Dataset & CLS last layer & All tokens last layer (attentive) & CLS+AP last layer (linear) & CLS+AP layers from all blocks (linear) & CLS+AP last layer (attentive) & CLS+AP layers from all blocks (attentive) \\\\\n",
      "\\midrule\n",
      "Natural (multi-domain) & STL-10 & 99.29 ± 0.51 & 0.01 ± 0.16 & -0.01 ± 0.12 & 0.03 ± 0.10 & \\underline{0.03 ± 0.08} & \\textbf{0.04 ± 0.17} \\\\\n",
      "Natural (multi-domain) & CIFAR-10 & 96.91 ± 1.93 & 0.42 ± 0.58 & 0.08 ± 0.11 & \\underline{0.61 ± 0.71} & 0.19 ± 0.29 & \\textbf{0.77 ± 0.79} \\\\\n",
      "Natural (multi-domain) & Caltech-101 & 95.57 ± 1.40 & 0.23 ± 0.52 & \\underline{0.43 ± 0.41} & 0.36 ± 0.63 & 0.09 ± 0.42 & \\textbf{0.88 ± 0.77} \\\\\n",
      "Natural (multi-domain) & PASCAL VOC 2007 & 87.82 ± 2.31 & -0.22 ± 1.24 & \\underline{1.38 ± 0.49} & \\textbf{1.46 ± 0.99} & 1.19 ± 0.88 & 1.24 ± 0.89 \\\\\n",
      "Natural (multi-domain) & ImageNet-1k & 81.40 ± 4.49 & 0.85 ± 1.43 & 0.33 ± 0.46 & \\underline{0.99 ± 1.75} & 0.15 ± 0.62 & \\textbf{1.24 ± 1.62} \\\\\n",
      "Natural (multi-domain) & CIFAR-100 & 85.45 ± 5.71 & 1.73 ± 1.33 & 0.61 ± 0.21 & \\underline{2.76 ± 2.48} & 0.87 ± 0.56 & \\textbf{3.33 ± 2.75} \\\\\n",
      "Natural (multi-domain) & Country-211 & 21.48 ± 6.35 & -0.83 ± 1.66 & 1.18 ± 0.54 & \\underline{3.26 ± 1.05} & 1.35 ± 0.65 & \\textbf{4.96 ± 1.37} \\\\\n",
      "Natural (single-domain) & Pets & 93.98 ± 2.36 & -0.23 ± 0.83 & -0.05 ± 0.41 & -2.01 ± 1.04 & \\underline{0.12 ± 0.53} & \\textbf{0.29 ± 0.76} \\\\\n",
      "Natural (single-domain) & Flowers & 98.03 ± 2.60 & \\underline{0.41 ± 0.93} & 0.40 ± 0.75 & -0.25 ± 0.57 & 0.06 ± 0.76 & \\textbf{0.46 ± 0.97} \\\\\n",
      "Natural (single-domain) & Stanford Cars & 77.81 ± 10.65 & \\textbf{8.97 ± 5.22} & 0.50 ± 1.07 & -0.86 ± 3.76 & 1.97 ± 1.95 & \\underline{6.35 ± 3.71} \\\\\n",
      "Natural (single-domain) & FGVC Aircraft & 55.69 ± 12.18 & \\textbf{9.27 ± 4.37} & -0.96 ± 2.22 & -1.62 ± 5.01 & 1.84 ± 2.09 & \\underline{6.43 ± 3.25} \\\\\n",
      "Natural (single-domain) & GTSRB & 71.51 ± 7.46 & \\textbf{18.02 ± 6.37} & 4.23 ± 2.60 & 8.76 ± 4.20 & 4.69 ± 2.41 & \\underline{13.47 ± 4.92} \\\\\n",
      "Natural (single-domain) & SVHN & 56.06 ± 5.91 & \\textbf{30.31 ± 5.08} & 6.94 ± 2.59 & 24.40 ± 4.41 & 7.39 ± 3.70 & \\underline{27.25 ± 4.24} \\\\\n",
      "Specialized & PCAM & 82.04 ± 2.15 & \\underline{5.03 ± 1.47} & 1.38 ± 0.56 & \\textbf{5.32 ± 1.62} & 2.66 ± 1.33 & 2.85 ± 2.53 \\\\\n",
      "Specialized & EuroSAT & 93.89 ± 2.52 & 3.38 ± 2.18 & 1.65 ± 1.17 & \\underline{4.08 ± 2.48} & 1.82 ± 1.22 & \\textbf{4.37 ± 2.41} \\\\\n",
      "Specialized & RESISC45 & 90.45 ± 1.69 & 4.07 ± 1.05 & 1.32 ± 0.74 & \\underline{4.53 ± 0.99} & 1.82 ± 0.59 & \\textbf{5.23 ± 1.10} \\\\\n",
      "Specialized & Diabetic Retinopathy & 45.80 ± 2.46 & 1.94 ± 1.90 & 1.55 ± 0.44 & \\underline{5.92 ± 2.03} & 1.86 ± 0.77 & \\textbf{6.86 ± 2.00} \\\\\n",
      "Structured & DTD & 75.99 ± 3.47 & 1.41 ± 2.19 & 1.18 ± 1.76 & \\underline{4.04 ± 2.19} & 2.53 ± 1.67 & \\textbf{4.05 ± 1.92} \\\\\n",
      "Structured & FER2013 & 59.08 ± 4.61 & \\underline{7.74 ± 2.15} & 2.18 ± 1.05 & 6.25 ± 1.19 & 3.61 ± 1.13 & \\textbf{10.05 ± 1.76} \\\\\n",
      "Structured & Dmlab & 44.91 ± 3.49 & \\textbf{13.69 ± 2.77} & 1.81 ± 0.45 & 7.92 ± 1.95 & 2.61 ± 1.65 & \\underline{10.68 ± 2.78} \\\\\n",
      "NaN & NaN & NaN & 2.750000 & 4.300000 & 2.800000 & 3.700000 & 1.450000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric_col in metrics_cols:\n",
    "    aggr_data = grouped_data[metric_col].agg([\"mean\", \"std\"]).reset_index()\n",
    "    \n",
    "    # Get means for ranking\n",
    "    mean_pivot = pd.pivot(\n",
    "        aggr_data,\n",
    "        index='dataset',\n",
    "        columns=\"Experiment\", \n",
    "        values=\"mean\"\n",
    "    ).loc[:, curr_order]\n",
    "    ranks = mean_pivot.iloc[:, 1:].rank(axis=1, ascending=False).mean()\n",
    "    \n",
    "    formatted_data = []\n",
    "    for idx, row in aggr_data.iterrows():\n",
    "        model = row['dataset']\n",
    "        exp = row['Experiment']\n",
    "        if model in mean_pivot.index and exp in mean_pivot.columns:\n",
    "            row_means = mean_pivot.loc[model].values\n",
    "            formatted = format_for_latex(row['mean'], row['std'], row_means[1:])\n",
    "            formatted_data.append({\n",
    "                'dataset': model,\n",
    "                'Experiment': exp,\n",
    "                'mean_std': formatted\n",
    "            })\n",
    "    \n",
    "    formatted_df = pd.DataFrame(formatted_data)\n",
    "    pivoted_aggr_data = pd.pivot(\n",
    "        formatted_df,\n",
    "        index='dataset',\n",
    "        columns=\"Experiment\",\n",
    "        values=\"mean_std\"\n",
    "    )\n",
    "    pivoted_aggr_data = pivoted_aggr_data.loc[:, curr_order]\n",
    "    pivoted_aggr_data = pivoted_aggr_data.sort_values(curr_order[-1], key=lambda x: x.apply(lambda val: float(val.split('±')[0].split('{')[-1].strip())))\n",
    "    \n",
    "    pivoted_aggr_data.index.name = None\n",
    "    pivoted_aggr_data.columns.name = None\n",
    "    pivoted_aggr_data = pivoted_aggr_data.reset_index(names='Dataset')\n",
    "    pivoted_aggr_data.insert(0, 'Category', ds_mapping.loc[pivoted_aggr_data[\"Dataset\"].tolist(), 'dataset_domain'].reset_index(drop=True))\n",
    "    pivoted_aggr_data['Dataset'] = ds_mapping.loc[pivoted_aggr_data[\"Dataset\"].tolist(), 'dataset_fmt'].reset_index(drop=True)\n",
    "\n",
    "    pivoted_aggr_data = pivoted_aggr_data.sort_values('Category', kind='stable')\n",
    "    tmp = pd.concat([pivoted_aggr_data, ranks.to_frame().T])\n",
    "    # latex_version_pivoted_aggr_data = pivoted_aggr_data.to_latex(escape=False, index=False)\n",
    "    latex_version_pivoted_aggr_data = tmp.to_latex(escape=False, index=False)\n",
    "\n",
    "    if SAVE:\n",
    "        filename = base_storing_path / 'tables_for_per_model_size_n_dataset_perf_gain' / f\"{metric_col}_aggr_over_models_table_v2.tex\"  # Creates filename based on metric_col\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(latex_version_pivoted_aggr_data)\n",
    "        print(f\"Stored latex table at {filename.parts[-4:]=}\")\n",
    "\n",
    "    else:\n",
    "        print(metric_col)\n",
    "        print()\n",
    "        print(latex_version_pivoted_aggr_data)\n",
    "        print()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rep2rep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
