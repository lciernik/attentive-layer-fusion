{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125d755d",
   "metadata": {},
   "source": [
    "# Do Intermediate Representations Help?\n",
    "This notebook compares vision transformer representation methods to determine whether using intermediate layers improves classification performance over final layer only.\n",
    "\n",
    "- **Data**\n",
    "    - **Input**: aggregated results `complete_set_of_run.pkl` with performance metrics\n",
    "    - **Models**:  9/11 vision transformers (OpenCLIP ViT, DINOv2, standard ViT, and potentially MAE)\n",
    "    - **Datasets**: 20 classification tasks\n",
    "- **Representation Sources:**\n",
    "    - Last layer: CLS token or all tokens\n",
    "    - Multi-layer: CLS + Average Pooling from:\n",
    "      - Middle & last blocks\n",
    "      - Quarterly blocks (1/4, 3/4 positions)\n",
    "      - All blocks\n",
    "- **Probing:**\n",
    "    - Linear classifiers on frozen features\n",
    "    - Attention mechanisms over token sequences\n",
    "- **Outputs**\n",
    "    1. **Figure 2**: Boxplots of accuracy gains across *base models*\n",
    "    2. **Statistical tests**: Wilcoxon signed-rank tests with FDR correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e6113-57ca-416a-9644-b152011f534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "from constants import BASE_PATH_PROJECT, FOLDER_SUBSTRING, experiment_with_probe_type_order_list, experiment_order_list\n",
    "from helper import init_plotting_params, save_or_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca097eb-1d2d-475e-bb5c-220c16915e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_plotting_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f93492-a1b6-4b56-8e0f-2c4af922cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = 'both'\n",
    "\n",
    "base_storing_path = BASE_PATH_PROJECT / f\"results_{FOLDER_SUBSTRING}_rebuttal/plots/do_intermediate_reps_help\"\n",
    "if SAVE:\n",
    "    base_storing_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb02f93-3da0-4c9b-b8f5-3454fd2ef73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs= pd.read_pickle(BASE_PATH_PROJECT / f'results_{FOLDER_SUBSTRING}_rebuttal/aggregated/complete_set_of_run.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f5099-d00b-412c-b2e3-3ea550f09707",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = all_runs.drop(index=all_runs[(all_runs['nr_layers'] == 1) & all_runs['contains_intermediate']].index).copy().reset_index(drop=True)\n",
    "all_runs = all_runs[all_runs['probe_type'].isin(['cae', 'linear'])].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e34011-2df2-42d6-b57e-280a5a63d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = sorted(all_runs['base_model'].unique())\n",
    "selected_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bf6eb-f3cb-4f9a-a1e5-4dc7519608ab",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c87582-d437-4f0c-bf0b-ff6d6bf7fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_ds = list(set(all_runs['dataset'].unique()) - set(['imagenet-subset-50k']))\n",
    "base_runs = all_runs[all_runs['model_size'] == 'base']\n",
    "base_runs = base_runs[base_runs['dataset'].isin(allowed_ds)].reset_index(drop=True).copy()\n",
    "base_runs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58414a2-8301-47e8-9374-fee7b8f115c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_runs['abs_perf_gain_test_lp_bal_acc1'] = base_runs['abs_perf_gain_test_lp_bal_acc1'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7109d1-d73d-4a2e-98f3-2bb88cd9ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_order = experiment_order_list[1:]\n",
    "curr_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac259bb-aa86-4778-bf0e-3bf2b3cb1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_runs = base_runs[base_runs['experiment'].isin(curr_order)]\n",
    "base_runs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8bb19-a73e-44d3-9e3a-f607c99b477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_for_attentive = base_runs[base_runs['experiment']=='CLS last layer'].copy().reset_index(drop=True)\n",
    "copy_for_attentive['task'] = \"attentive_probe\"\n",
    "\n",
    "base_runs = pd.concat([base_runs, copy_for_attentive]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bf4cd-d197-4896-9a21-fbe06b2a3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_runs[['task', 'Experiment']].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae35bff-e8a4-4d5b-b900-f85c869869a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_runs['base_model_fmt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2abcd-c763-4a69-bb93-c4f1e7d687f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab20c = plt.cm.tab20c.colors  \n",
    "palette_list = list(tab20c[:8])\n",
    "reversed_palette = []\n",
    "for group_start in [0, 4]:\n",
    "    group = palette_list[group_start:group_start+4]\n",
    "    reversed_group = group[::-1]  # reverse the group\n",
    "    reversed_palette.extend(reversed_group)\n",
    "\n",
    "reversed_palette = [tab20c[17]] + reversed_palette\n",
    "\n",
    "\n",
    "for order in [\n",
    "    ['CLIP-B-16', 'DINOv2-B-14', 'ViT-B-16', 'MAE-B-16'],\n",
    "    ['CLIP-B-16', 'DINOv2-B-14', 'ViT-B-16']\n",
    "]:\n",
    "\n",
    "    plt.figure(figsize=(11, 5.5))\n",
    "\n",
    "    ax = sns.boxplot(\n",
    "        base_runs,\n",
    "        x=\"base_model_fmt\",\n",
    "        y=\"abs_perf_gain_test_lp_bal_acc1\",\n",
    "        order=order,\n",
    "        hue=\"Experiment\",\n",
    "        hue_order=experiment_with_probe_type_order_list[2:],\n",
    "        palette=reversed_palette,\n",
    "        fliersize=3,\n",
    "        showfliers=False\n",
    "    )\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Absolute accuracy gain [pp]\")\n",
    "    sns.move_legend(ax, bbox_to_anchor=(1.05, 1), loc='upper left', title=False)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = [\n",
    "        Line2D([0], [0], marker='', color='white', linestyle='', alpha=0),\n",
    "        handles[0],\n",
    "        Line2D([0], [0], marker='', color='white', linestyle='', alpha=0),\n",
    "        Line2D([0], [0], marker='', color='white', linestyle='', alpha=0),\n",
    "        Line2D([0], [0], marker='', color='white', linestyle='', alpha=0),\n",
    "        Line2D([0], [0], marker='', color='white', linestyle='', alpha=0)\n",
    "    ]\n",
    "    new_labels = [\n",
    "        \"Attentive probe (all tokens)\",\n",
    "        # labels[0].split(\" (\")[0] + \" (AAT)\",\n",
    "        # labels[0].split(\" (\")[0],\n",
    "        \"Last layer\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"Linear probe (CLS & AP)\"\n",
    "    ]\n",
    "    \n",
    "    prev_name = None\n",
    "    for k, (curr_handle, curr_label) in enumerate(zip(handles, labels)):\n",
    "        if k==0:\n",
    "            continue\n",
    "    \n",
    "        if k>0 and prev_name is not None and (\"linear\" in prev_name and \"attentive\" in curr_label):\n",
    "            new_handles.append(Line2D([0], [0], marker='', color='white', linestyle='', alpha=0))\n",
    "            new_labels.append(\"Attentive probe (CLS & AP)\")\n",
    "    \n",
    "        new_handles.append(curr_handle)\n",
    "        full_label = curr_label\n",
    "        curr_label = curr_label.split(\" (\")[0]\n",
    "        curr_label = curr_label.replace(\"CLS+AP l\", \"L\")\n",
    "        if curr_label == \"Layers from middle & last blocks\":\n",
    "            curr_label = \"+ middle block\"\n",
    "        elif curr_label == \"Layers from quarterly blocks\":\n",
    "            curr_label = \"+ 1/4th and 3/4th blocks\"\n",
    "        elif curr_label == \"Layers from all blocks\":\n",
    "            curr_label = \"All blocks + last layer\"\n",
    "            \n",
    "        new_labels.append(curr_label)\n",
    "        prev_name = full_label\n",
    "\n",
    "    legend = ax.legend(new_handles, new_labels, bbox_to_anchor=(0.5, 0.935), loc='lower center', ncols=3, frameon=False)\n",
    "    \n",
    "    ax.axhline(0, ls=':', color=\"grey\", zorder=-1)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    suffix = \"_with_mae\" if len(order)==4 else \"\"\n",
    "    fn = base_storing_path / f'boxplot_base_models{suffix}_v6.pdf'\n",
    "    save_or_show(plt.gcf(), fn, SAVE, show_path=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba2801",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9fd9e-14e9-47e4-99f3-29195c40dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr_bh(pvals):\n",
    "    pvalues = np.array(pvals)\n",
    "    n_tests = len(pvals)\n",
    "    sorted_indices = np.argsort(pvals)\n",
    "    sorted_pvals = pvalues[sorted_indices]\n",
    "    \n",
    "    corrected_pvals = np.zeros_like(pvals)\n",
    "    for i in range(n_tests-1, -1, -1):\n",
    "        corrected_pvals[sorted_indices[i]] = min(1.0, sorted_pvals[i] * n_tests / (i + 1))\n",
    "        if i < n_tests - 1:\n",
    "            corrected_pvals[sorted_indices[i]] = min(corrected_pvals[sorted_indices[i]], \n",
    "                                                    corrected_pvals[sorted_indices[i+1]])\n",
    "    return corrected_pvals\n",
    "\n",
    "\n",
    "exp_pairs = [\n",
    "    (\"CLS+AP layers from all blocks (attentive)\", \"CLS+AP last layer (attentive)\"),\n",
    "    (\"CLS+AP layers from all blocks (linear)\", \"CLS+AP last layer (linear)\"),\n",
    "    (\"CLS+AP layers from all blocks (attentive)\", \"CLS+AP layers from all blocks (linear)\"),\n",
    "    (\"CLS+AP layers from all blocks (attentive)\", \"All tokens last layer (attentive)\"),\n",
    "    \n",
    "]\n",
    "alpha = 0.05\n",
    "\n",
    "pvalues = []\n",
    "comb_index = []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "for mid, mid_data in base_runs.groupby(\"base_model\"):\n",
    "    for exp1, exp2 in exp_pairs:\n",
    "        exp1_data = pd.to_numeric(mid_data[mid_data['Experiment'] == exp1].sort_values('dataset')[\"abs_perf_gain_test_lp_bal_acc1\"]).values\n",
    "        exp2_data = pd.to_numeric(mid_data[mid_data['Experiment'] == exp2].sort_values('dataset')[\"abs_perf_gain_test_lp_bal_acc1\"]).values\n",
    "        statistic, pval = wilcoxon(exp1_data, exp2_data, alternative='greater')\n",
    "\n",
    "        pvalues.append(pval)\n",
    "        comb_index.append((mid, (exp1, exp2))) \n",
    "\n",
    "adj_pvalues = fdr_bh(pvalues)\n",
    "statistical_testing = pd.DataFrame({\n",
    "    \"adj_pvalues\": adj_pvalues, \n",
    "    \"regected\": adj_pvalues < alpha, \n",
    "    \"base_model\": [val[0] for val in comb_index],\n",
    "    \"exp1\": [val[1][0] for val in comb_index],\n",
    "    \"exp2\": [val[1][1] for val in comb_index],\n",
    "})\n",
    "if SAVE:\n",
    "    fn = base_storing_path / f'statistical_tests.csv'\n",
    "    statistical_testing.sort_values('adj_pvalues').to_csv(fn)\n",
    "    print(f\"Stored statistical testin...\")\n",
    "    display(statistical_testing)\n",
    "else:\n",
    "    display(statistical_testing.sort_values('adj_pvalues'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
